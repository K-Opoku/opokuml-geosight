{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-Opoku/opokuml-geosight/blob/main/full_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUf0zfid3OWo",
        "outputId": "acec1cff-2e95-4e2f-a2c4-0a3781659278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1tRr9nO4tOI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dataset_path='/content/drive/MyDrive/opokuml_geosight'\n",
        "os.makedirs(dataset_path,exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c4GZXCv0Pqcw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw9nYwRvA85n"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwQ23uvoA9lB",
        "outputId": "cce0e5bd-4fc9-4c72-ed53-60cc56cbf884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EuroSAT.zip already exists, skipping download.\n",
            "EuroSAT dataset already extracted, skipping unzip.\n"
          ]
        }
      ],
      "source": [
        "'''!wget --no-check-certificate -P /content/drive/MyDrive/opokuml_geosight https://madm.dfki.de/files/sentinel/EuroSAT.zip\n",
        "!unzip /content/drive/MyDrive/opokuml_geosight/EuroSAT.zip -d /content/drive/MyDrive/opokuml_geosight'''\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/opokuml_geosight/EuroSAT.zip\"\n",
        "dataset_dir = \"/content/drive/MyDrive/opokuml_geosight/2750\"\n",
        "\n",
        "# Download only if zip doesn't exist\n",
        "if not os.path.exists(zip_path):\n",
        "    !wget --no-check-certificate -P /content/drive/MyDrive/opokuml_geosight https://madm.dfki.de/files/sentinel/EuroSAT.zip\n",
        "else:\n",
        "    print(\"EuroSAT.zip already exists, skipping download.\")\n",
        "\n",
        "# Unzip only if dataset folder doesn't exist\n",
        "if not os.path.exists(dataset_dir):\n",
        "    !unzip /content/drive/MyDrive/opokuml_geosight/EuroSAT.zip -d /content/drive/MyDrive/opokuml_geosight\n",
        "else:\n",
        "    print(\"EuroSAT dataset already extracted, skipping unzip.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mUxHi4CCrZJ",
        "outputId": "133f94f9-a8ae-4849-e95a-56104f426dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data already exists at /content/eurosat_fast. Skipping copy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# 1. Your SLOW Google Drive path (Where the images are now)\n",
        "# IMPORTANT: Change this to match your actual Drive folder name!\n",
        "source_dir = '/content/drive/MyDrive/data/eurosat'\n",
        "\n",
        "# 2. The FAST Local path (Where we want to move them)\n",
        "dest_dir = '/content/eurosat_fast'\n",
        "\n",
        "# --- THE COPY LOGIC ---\n",
        "if os.path.exists(dest_dir):\n",
        "    print(f\"‚úÖ Data already exists at {dest_dir}. Skipping copy.\")\n",
        "else:\n",
        "    print(f\"üöÄ Copying data from Drive to Local Disk... (This takes 1-2 mins)\")\n",
        "    try:\n",
        "        shutil.copytree(source_dir, dest_dir)\n",
        "        print(f\"‚úÖ Done! Data is now ready at: {dest_dir}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ERROR: Could not find your source folder: {source_dir}\")\n",
        "        print(\"Please check your Google Drive path!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac-pMC-Df05w"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjy0CN0lf7Ne"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class OpokuEuroSAT(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths   # plural, consistent everywhere\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bzEOM94Nifw"
      },
      "outputs": [],
      "source": [
        "# Defining transforms\n",
        "train_transform=transforms.Compose([transforms.Resize((224,224),interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomRotation(15),\n",
        "                                    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "                                    transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "clean_transform=transforms.Compose([transforms.Resize((224,224)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Source (Where they are now in Drive)\n",
        "source_dir = \"/content/drive/MyDrive/opokuml_geosight/2750\"\n",
        "\n",
        "# Destination (Where your code expects them)\n",
        "dest_dir = \"/content/eurosat_fast/2750\"\n",
        "\n",
        "if os.path.exists(source_dir):\n",
        "    print(f\"üöÄ Copying files from Drive to Local Runtime...\")\n",
        "    shutil.copytree(source_dir, dest_dir, dirs_exist_ok=True)\n",
        "    print(\"‚úÖ Files copied! Your original code will work now.\")\n",
        "else:\n",
        "    print(\"‚ùå Error: I can't find the '2750' folder in your Drive path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTQI39OCtCXC",
        "outputId": "3b68b943-54c6-46f8-eb42-7be1167449ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Copying files from Drive to Local Runtime...\n",
            "‚úÖ Files copied! Your original code will work now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5FBIlWSgAmN",
        "outputId": "2dff0968-e6e6-4865-e0a1-4b31baebf14c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gathering files\n",
            "Total Images: 27000\n",
            "Train Set:    18900\n",
            "Val Set:      4050\n",
            "Test Set:     4050\n"
          ]
        }
      ],
      "source": [
        "# Organising data paths\n",
        "root_dir = '/content/eurosat_fast/2750'  # <--- The fast local path\n",
        "\n",
        "# üîë Initialize lists here\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "\n",
        "if not os.path.exists(root_dir):\n",
        "    print(f'The path {root_dir} does not exist')\n",
        "else:\n",
        "    classes = sorted(os.listdir(root_dir))\n",
        "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "\n",
        "    print('Gathering files')\n",
        "    for cls_name in classes:\n",
        "        cls_folder = os.path.join(root_dir, cls_name)\n",
        "        if os.path.isdir(cls_folder):\n",
        "            for img_name in os.listdir(cls_folder):\n",
        "                if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    all_image_paths.append(os.path.join(cls_folder, img_name))\n",
        "                    all_labels.append(class_to_idx[cls_name])\n",
        "\n",
        "# Split into train/val/test\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    all_image_paths,\n",
        "    all_labels,\n",
        "    test_size=0.3,\n",
        "    stratify=all_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths,\n",
        "    temp_labels,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total Images: {len(all_image_paths)}\")\n",
        "print(f\"Train Set:    {len(train_paths)}\")\n",
        "print(f\"Val Set:      {len(val_paths)}\")\n",
        "print(f\"Test Set:     {len(test_paths)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Create the Dataset Objects\n",
        "# (We assume 'OpokuEuroSAT', 'train_transform', and 'clean_transform' are defined in your cells above)\n",
        "train_dataset = OpokuEuroSAT(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset   = OpokuEuroSAT(val_paths, val_labels, transform=clean_transform)\n",
        "test_dataset  = OpokuEuroSAT(test_paths, test_labels, transform=clean_transform)\n",
        "\n",
        "# 2. Create DataLoaders\n",
        "# Batch Size 32 is the \"Safe Zone\" for your GPU\n",
        "# num_workers=2 makes loading fast from the local SSD\n",
        "print(\"‚öôÔ∏è Building DataLoaders...\")\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"‚úÖ Data is ready to train!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isXINE8IavAb",
        "outputId": "5a4e7cf6-4aab-4d04-9449-e1b1764e1a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Building DataLoaders...\n",
            "‚úÖ Data is ready to train!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class EuroSATConvNeXt_Unfrozen(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(EuroSATConvNeXt_Unfrozen, self).__init__()\n",
        "\n",
        "        # Load the Backbone (ImageNet Weights)\n",
        "        backbone = models.convnext_tiny(weights='DEFAULT')\n",
        "        self.features = backbone.features\n",
        "\n",
        "        # UNFREEZE: Allow the whole model to learn\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # The Head (Classifier)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.norm = nn.LayerNorm(768)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tXF0Bzj8auus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class EuroSATConvNeXt_Unfrozen(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(EuroSATConvNeXt_Unfrozen, self).__init__()\n",
        "\n",
        "        # Load the Backbone (ImageNet Weights)\n",
        "        backbone = models.convnext_tiny(weights='DEFAULT')\n",
        "        self.features = backbone.features\n",
        "\n",
        "        # UNFREEZE: Allow the whole model to learn\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # The Head (Classifier)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.norm = nn.LayerNorm(768)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CXK8aWExa0Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import sys\n",
        "import copy\n",
        "\n",
        "def make_model(learning_rate=0.0001, device='cuda'):\n",
        "    \"\"\"Creates the model and optimizer with safe settings.\"\"\"\n",
        "    model = EuroSATConvNeXt_Unfrozen(num_classes=10).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    return model, optimizer\n",
        "\n",
        "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device):\n",
        "    \"\"\"Runs the training loop with a visual progress bar.\"\"\"\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    print(f\"üöÄ Starting Training for {num_epochs} Epochs on {device}...\")\n",
        "\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # --- Training Phase ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Visual Progress Bar (Updates every 50 batches)\n",
        "            if (i+1) % 50 == 0 or (i+1) == len(train_loader):\n",
        "                sys.stdout.write(f\"\\r   >> Batch {i+1}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"\\n   ‚úÖ Result: Train Acc: {epoch_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_acc'].append(epoch_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            print(f\"   üèÜ New Best Accuracy! ({best_acc:.4f} --> {val_acc:.4f}) Saving...\")\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), 'best_eurosat_model.pth')\n",
        "\n",
        "    print(f\"\\nüèÅ Training Complete. Best Validation Accuracy: {best_acc:.4f}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return history"
      ],
      "metadata": {
        "id": "vN5Y5KRea88Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# --- 1. DELETE THE BAD FILE ---\n",
        "bad_file = '/content/eurosat_fast/2750/PermanentCrop/PermanentCrop_670.jpg'\n",
        "\n",
        "if os.path.exists(bad_file):\n",
        "    os.remove(bad_file)\n",
        "    print(f\"‚úÖ FOUND and DELETED the bad file: {bad_file}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è The bad file is already gone.\")\n",
        "\n",
        "# --- 2. REFRESH THE DATA LISTS (Must do this to remove the bad path) ---\n",
        "root_dir = '/content/eurosat_fast/2750'\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "classes = sorted(os.listdir(root_dir))\n",
        "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "\n",
        "# Re-scan folders (now without the bad file)\n",
        "for cls_name in classes:\n",
        "    cls_folder = os.path.join(root_dir, cls_name)\n",
        "    if os.path.isdir(cls_folder):\n",
        "        for img_name in os.listdir(cls_folder):\n",
        "            if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                all_image_paths.append(os.path.join(cls_folder, img_name))\n",
        "                all_labels.append(class_to_idx[cls_name])\n",
        "\n",
        "# --- 3. RE-SPLIT DATA ---\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    all_image_paths, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
        ")\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
        ")\n",
        "\n",
        "# --- 4. RE-BUILD LOADERS ---\n",
        "print(\"‚öôÔ∏è Updating DataLoaders...\")\n",
        "# (Assuming OpokuEuroSAT class still exists in memory)\n",
        "train_dataset = OpokuEuroSAT(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset   = OpokuEuroSAT(val_paths, val_labels, transform=clean_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"üöÄ FIXED! You can now run the Training Cell below.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Z3a3E4ejDi",
        "outputId": "c2366993-61d1-4061-ee29-0a91feee319c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ FOUND and DELETED the bad file: /content/eurosat_fast/2750/PermanentCrop/PermanentCrop_670.jpg\n",
            "‚öôÔ∏è Updating DataLoaders...\n",
            "üöÄ FIXED! You can now run the Training Cell below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# 1. Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 2. Make Model\n",
        "model, optimizer = make_model(learning_rate=0.0001, device=device)\n",
        "\n",
        "# 3. Train\n",
        "history = train_and_evaluate(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    num_epochs=10,\n",
        "    device=device\n",
        ")\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "pOxlGQfgbAkX",
        "outputId": "654e6bed-c846-41d8-f623-8fdb037a3e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# 1. Setup\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\ncriterion = nn.CrossEntropyLoss()\\n# 2. Make Model\\nmodel, optimizer = make_model(learning_rate=0.0001, device=device)\\n\\n# 3. Train\\nhistory = train_and_evaluate(\\n    model=model,\\n    optimizer=optimizer,\\n    train_loader=train_loader,\\n    val_loader=val_loader,\\n    criterion=criterion,\\n    num_epochs=10,\\n    device=device\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1. Define where you want to save it on Google Drive\n",
        "# (We use the same folder where your dataset zip is)\n",
        "drive_folder = '/content/drive/MyDrive/opokuml_geosight'\n",
        "source_file = 'best_eurosat_model.pth'\n",
        "destination_file = os.path.join(drive_folder, 'eurosat_97_acc.pth') # Give it a cool name!\n",
        "\n",
        "# 2. Copy the file\n",
        "if os.path.exists(source_file):\n",
        "    print(f\"üöÄ Saving model to Google Drive: {destination_file}...\")\n",
        "    shutil.copy(source_file, destination_file)\n",
        "    print(\"‚úÖ SAVED! Your model is safe. You can close the tab now.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Error: Could not find the model file yet. Did training start?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8NLQ3mFelE8",
        "outputId": "51823dd6-bfec-4318-b747-c07e6baaaa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Error: Could not find the model file yet. Did training start?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "jfLiqlmSzFeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1. Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "model = EuroSATConvNeXt_Unfrozen(num_classes=10)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/opokuml_geosight/eurosat_97_acc.pth'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# 2. Check on Test Data\n",
        "correct = 0\n",
        "total = 0\n",
        "print(\"üìù Running Final Exam on Test Set...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader: # Note: We use test_loader here\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "final_acc = correct / total\n",
        "print(\"-\" * 30)\n",
        "print(f\"üèÜ OFFICIAL TEST ACCURACY: {final_acc:.4f} ({final_acc*100:.2f}%)\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VyiITPorKBV",
        "outputId": "6ea7b1b2-7fe1-49ce-ffc6-378afac9a4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Running Final Exam on Test Set...\n",
            "------------------------------\n",
            "üèÜ OFFICIAL TEST ACCURACY: 0.9886 (98.86%)\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting model to Onnx"
      ],
      "metadata": {
        "id": "-ubLkC0Tszyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxscript onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlyTJjwZ2_Xl",
        "outputId": "aeeaa473-ebb2-4dd0-a3ce-f696b2fb0109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, onnx, coloredlogs, onnxruntime, onnx_ir, onnxscript\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.20.0 onnx_ir-0.1.13 onnxruntime-1.23.2 onnxscript-0.5.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EuroSATConvNeXt_Unfrozen(num_classes=10)\n",
        "model.load_state_dict(torch.load(\n",
        "    '/content/drive/MyDrive/opokuml_geosight/eurosat_97_acc.pth',\n",
        "    map_location=device   # ensures weights load correctly on CPU/GPU\n",
        "))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# creating a dummy input\n",
        "dummy_input=torch.randn(1,3,224,224).to(device)\n",
        "\n",
        "# Exporting with torch.onnx.export\n",
        "torch.onnx.export(model,\n",
        "                  dummy_input,\n",
        "                  'eurosat.onnx',\n",
        "                  export_params=True,\n",
        "                  opset_version=11,\n",
        "                  do_constant_folding=True,\n",
        "                  input_names=['input'],\n",
        "                  output_names=['output'],\n",
        "                  dynamic_axes={'input':{0:'batch_size'}, 'output':{0:'batch_size'}}\n",
        "                  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPYI1K65s60_",
        "outputId": "139749aa-dbc7-4c5d-d6a8-8d8b0f94f144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2655390643.py:14: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(model,\n",
            "W1226 16:07:35.857000 177 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `EuroSATConvNeXt_Unfrozen([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `EuroSATConvNeXt_Unfrozen([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ‚úÖ\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n",
            "WARNING:onnxscript.optimizer._constant_folding:Skipping constant folding for op SequenceEmpty with multiple outputs.\n",
            "WARNING:onnxscript.optimizer._constant_folding:Skipping constant folding for op SequenceEmpty with multiple outputs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 18},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.0+cu126',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"input\"<FLOAT,[s77,3,224,224]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"output\"<FLOAT,[1,10]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"features.0.0.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.0.1.weight\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.0.1.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.0.layer_scale\"<FLOAT,[96,1,1]>{TorchTensor(...)},\n",
              "                %\"features.1.0.block.0.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.0.block.2.weight\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.0.block.2.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.0.block.3.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.1.0.block.5.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.1.layer_scale\"<FLOAT,[96,1,1]>{TorchTensor(...)},\n",
              "                %\"features.1.1.block.0.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.1.block.2.weight\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.1.block.2.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.1.block.3.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.1.1.block.5.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.2.layer_scale\"<FLOAT,[96,1,1]>{TorchTensor(...)},\n",
              "                %\"features.1.2.block.0.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.2.block.2.weight\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.2.block.2.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.1.2.block.3.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.1.2.block.5.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.2.0.weight\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.2.0.bias\"<FLOAT,[96]>{TorchTensor(...)},\n",
              "                %\"features.2.1.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.0.layer_scale\"<FLOAT,[192,1,1]>{TorchTensor(...)},\n",
              "                %\"features.3.0.block.0.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.0.block.2.weight\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.0.block.2.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.0.block.3.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.3.0.block.5.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.1.layer_scale\"<FLOAT,[192,1,1]>{TorchTensor(...)},\n",
              "                %\"features.3.1.block.0.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.1.block.2.weight\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.1.block.2.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.1.block.3.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.3.1.block.5.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.2.layer_scale\"<FLOAT,[192,1,1]>{TorchTensor(...)},\n",
              "                %\"features.3.2.block.0.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.2.block.2.weight\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.2.block.2.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.3.2.block.3.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.3.2.block.5.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.4.0.weight\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.4.0.bias\"<FLOAT,[192]>{TorchTensor(...)},\n",
              "                %\"features.4.1.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.0.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.0.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.0.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.0.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.0.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.1.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.1.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.1.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.1.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.1.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.2.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.2.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.2.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.2.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.2.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.3.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.3.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.3.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.3.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.3.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.4.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.4.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.4.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.4.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.4.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.5.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.5.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.5.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.5.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.5.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.6.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.6.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.6.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.6.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.6.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.7.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.7.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.7.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.7.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.7.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.8.layer_scale\"<FLOAT,[384,1,1]>{TorchTensor(...)},\n",
              "                %\"features.5.8.block.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.8.block.2.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.8.block.2.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.5.8.block.5.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.6.0.weight\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.6.0.bias\"<FLOAT,[384]>{TorchTensor(...)},\n",
              "                %\"features.6.1.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.0.layer_scale\"<FLOAT,[768,1,1]>{TorchTensor(...)},\n",
              "                %\"features.7.0.block.0.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.0.block.2.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.0.block.2.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.0.block.5.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.1.layer_scale\"<FLOAT,[768,1,1]>{TorchTensor(...)},\n",
              "                %\"features.7.1.block.0.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.1.block.2.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.1.block.2.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.1.block.5.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.2.layer_scale\"<FLOAT,[768,1,1]>{TorchTensor(...)},\n",
              "                %\"features.7.2.block.0.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.2.block.2.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.2.block.2.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"features.7.2.block.5.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"norm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"classifier.bias\"<FLOAT,[10]>{TorchTensor<FLOAT,[10]>(Parameter containing: tensor([-0.0109, -0.0281,  0.0186, -0.0080, -0.0104, -0.0351, -0.0160, -0.0071, -0.0217,  0.0017], device='cuda:0', requires_grad=True), name='classifier.bias')},\n",
              "                %\"features.0.0.weight\"<FLOAT,[96,3,4,4]>{TorchTensor(...)},\n",
              "                %\"features.1.0.block.0.weight\"<FLOAT,[96,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.1.1.block.0.weight\"<FLOAT,[96,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.1.2.block.0.weight\"<FLOAT,[96,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.2.1.weight\"<FLOAT,[192,96,2,2]>{TorchTensor(...)},\n",
              "                %\"features.3.0.block.0.weight\"<FLOAT,[192,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.3.1.block.0.weight\"<FLOAT,[192,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.3.2.block.0.weight\"<FLOAT,[192,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.4.1.weight\"<FLOAT,[384,192,2,2]>{TorchTensor(...)},\n",
              "                %\"features.5.0.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.0.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.1.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.1.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.2.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.2.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.3.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.3.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.4.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.4.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.5.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.5.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.6.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.6.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.7.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.7.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.5.8.block.0.weight\"<FLOAT,[384,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.5.8.block.3.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
              "                %\"features.6.1.weight\"<FLOAT,[768,384,2,2]>{TorchTensor(...)},\n",
              "                %\"features.7.0.block.0.weight\"<FLOAT,[768,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.7.0.block.3.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"features.7.1.block.0.weight\"<FLOAT,[768,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.7.1.block.3.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"features.7.2.block.0.weight\"<FLOAT,[768,1,7,7]>{TorchTensor(...)},\n",
              "                %\"features.7.2.block.3.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"classifier.weight\"<FLOAT,[10,768]>{TorchTensor(...)},\n",
              "                %\"val_4\"<FLOAT,[96,384]>{Tensor(...)},\n",
              "                %\"val_13\"<FLOAT,[384,96]>{Tensor(...)},\n",
              "                %\"val_17\"<FLOAT,[96,384]>{Tensor(...)},\n",
              "                %\"val_26\"<FLOAT,[384,96]>{Tensor(...)},\n",
              "                %\"val_30\"<FLOAT,[96,384]>{Tensor(...)},\n",
              "                %\"val_39\"<FLOAT,[384,96]>{Tensor(...)},\n",
              "                %\"val_45\"<FLOAT,[192,768]>{Tensor(...)},\n",
              "                %\"val_54\"<FLOAT,[768,192]>{Tensor(...)},\n",
              "                %\"val_58\"<FLOAT,[192,768]>{Tensor(...)},\n",
              "                %\"val_67\"<FLOAT,[768,192]>{Tensor(...)},\n",
              "                %\"val_71\"<FLOAT,[192,768]>{Tensor(...)},\n",
              "                %\"val_80\"<FLOAT,[768,192]>{Tensor(...)},\n",
              "                %\"val_86\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_95\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_99\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_108\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_112\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_121\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_125\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_134\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_138\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_147\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_151\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_160\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_164\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_173\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_177\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_186\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_190\"<FLOAT,[384,1536]>{Tensor(...)},\n",
              "                %\"val_199\"<FLOAT,[1536,384]>{Tensor(...)},\n",
              "                %\"val_205\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_214\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_218\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_227\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_231\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_240\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_244\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_244')},\n",
              "                %\"rank_tensor\"<INT64,[1]>{Tensor<INT64,[1]>(array([4]), name='rank_tensor')},\n",
              "                %\"val_250\"<INT64,[2]>{Tensor<INT64,[2]>(array([  1, 768]), name='val_250')},\n",
              "                %\"val_6\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1.4142135, dtype=float32), name='val_6')},\n",
              "                %\"val_9\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1., dtype=float32), name='val_9')},\n",
              "                %\"val_11\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(0.5, dtype=float32), name='val_11')},\n",
              "                %\"val_245\"<INT64,[4]>{Tensor<INT64,[4]>(array([  1, 768,   1,   1]), name='val_245')},\n",
              "                %\"val_246\"<INT64,[4]>{Tensor<INT64,[4]>(array([768,   1, 768, 768]), name='val_246')},\n",
              "                %\"neg_1\"<INT64,[1]>{Tensor<INT64,[1]>(array([-1]), name='neg_1')},\n",
              "                %\"indices\"<INT64,[]>{Tensor<INT64,[]>(array(0), name='indices')},\n",
              "                %\"rank_0\"<INT64,[]>{Tensor<INT64,[]>(array(4), name='rank_0')},\n",
              "                %\"int64_1_cast\"<INT64,[]>{Tensor<INT64,[]>(array(1), name='int64_1_cast')},\n",
              "                %\"tmp_14\"<FLOAT,[1]>{Tensor<FLOAT,[1]>(array([1.], dtype=float32), name='tmp_14')}\n",
              "            ),\n",
              "        ) {\n",
              "              0 |  # node_conv2d\n",
              "                   %\"conv2d\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Conv(%\"input\", %\"features.0.0.weight\"{...}, %\"features.0.0.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(4, 4), dilations=(1, 1)}\n",
              "              1 |  # node_permute\n",
              "                   %\"permute\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d\") {perm=(0, 2, 3, 1)}\n",
              "              2 |  # node_layer_norm\n",
              "                   %\"layer_norm\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute\", %\"features.0.1.weight\"{...}, %\"features.0.1.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "              3 |  # node_permute_1\n",
              "                   %\"permute_1\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Transpose(%\"layer_norm\") {perm=(0, 3, 1, 2)}\n",
              "              4 |  # node_conv2d_1\n",
              "                   %\"conv2d_1\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Conv(%\"permute_1\", %\"features.1.0.block.0.weight\"{...}, %\"features.1.0.block.0.bias\"{...}) {group=96, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              5 |  # node_permute_2\n",
              "                   %\"permute_2\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_1\") {perm=(0, 2, 3, 1)}\n",
              "              6 |  # node_layer_norm_1\n",
              "                   %\"layer_norm_1\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_2\", %\"features.1.0.block.2.weight\"{...}, %\"features.1.0.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "              7 |  # node_MatMul_1\n",
              "                   %\"val_5\"<FLOAT,[s77,56,56,384]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_1\", %\"val_4\"{...})\n",
              "              8 |  # node_linear\n",
              "                   %\"linear\"<FLOAT,[s77,56,56,384]> ‚¨ÖÔ∏è ::Add(%\"val_5\", %\"features.1.0.block.3.bias\"{...})\n",
              "              9 |  # node_Div_3\n",
              "                   %\"val_7\"<FLOAT,[s77,56,56,384]> ‚¨ÖÔ∏è ::Div(%\"linear\", %\"val_6\"{1.4142135381698608})\n",
              "             10 |  # node_Erf_4\n",
              "                   %\"val_8\"<FLOAT,[s77,56,56,384]> ‚¨ÖÔ∏è ::Erf(%\"val_7\")\n",
              "             11 |  # node_Add_6\n",
              "                   %\"val_10\"<FLOAT,[s77,56,56,384]> ‚¨ÖÔ∏è ::Add(%\"val_8\", %\"val_9\"{1.0})\n",
              "             12 |  # node_Mul_8\n",
              "                   %\"val_12\"<FLOAT,[s77,56,56,384]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_10\")\n",
              "             13 |  # node_gelu\n",
              "                   %\"gelu\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Mul(%\"linear\", %\"val_12\")\n",
              "             14 |  # node_MatMul_10\n",
              "                   %\"val_14\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::MatMul(%\"gelu\", %\"val_13\"{...})\n",
              "             15 |  # node_linear_1\n",
              "                   %\"linear_1\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::Add(%\"val_14\", %\"features.1.0.block.5.bias\"{...})\n",
              "             16 |  # node_permute_3\n",
              "                   %\"permute_3\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Transpose(%\"linear_1\") {perm=(0, 3, 1, 2)}\n",
              "             17 |  # node_mul_55\n",
              "                   %\"mul_55\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Mul(%\"features.1.0.layer_scale\"{...}, %\"permute_3\")\n",
              "             18 |  # node_add_90\n",
              "                   %\"add_90\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Add(%\"mul_55\", %\"permute_1\")\n",
              "             19 |  # node_conv2d_2\n",
              "                   %\"conv2d_2\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Conv(%\"add_90\", %\"features.1.1.block.0.weight\"{...}, %\"features.1.1.block.0.bias\"{...}) {group=96, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             20 |  # node_permute_4\n",
              "                   %\"permute_4\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_2\") {perm=(0, 2, 3, 1)}\n",
              "             21 |  # node_layer_norm_2\n",
              "                   %\"layer_norm_2\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_4\", %\"features.1.1.block.2.weight\"{...}, %\"features.1.1.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "             22 |  # node_MatMul_12\n",
              "                   %\"val_18\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_2\", %\"val_17\"{...})\n",
              "             23 |  # node_linear_2\n",
              "                   %\"linear_2\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Add(%\"val_18\", %\"features.1.1.block.3.bias\"{...})\n",
              "             24 |  # node_Div_14\n",
              "                   %\"val_20\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Div(%\"linear_2\", %\"val_6\"{1.4142135381698608})\n",
              "             25 |  # node_Erf_15\n",
              "                   %\"val_21\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Erf(%\"val_20\")\n",
              "             26 |  # node_Add_17\n",
              "                   %\"val_23\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Add(%\"val_21\", %\"val_9\"{1.0})\n",
              "             27 |  # node_Mul_19\n",
              "                   %\"val_25\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_23\")\n",
              "             28 |  # node_gelu_1\n",
              "                   %\"gelu_1\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Mul(%\"linear_2\", %\"val_25\")\n",
              "             29 |  # node_MatMul_21\n",
              "                   %\"val_27\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_1\", %\"val_26\"{...})\n",
              "             30 |  # node_linear_3\n",
              "                   %\"linear_3\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::Add(%\"val_27\", %\"features.1.1.block.5.bias\"{...})\n",
              "             31 |  # node_permute_5\n",
              "                   %\"permute_5\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Transpose(%\"linear_3\") {perm=(0, 3, 1, 2)}\n",
              "             32 |  # node_mul_98\n",
              "                   %\"mul_98\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Mul(%\"features.1.1.layer_scale\"{...}, %\"permute_5\")\n",
              "             33 |  # node_add_136\n",
              "                   %\"add_136\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Add(%\"mul_98\", %\"add_90\")\n",
              "             34 |  # node_conv2d_3\n",
              "                   %\"conv2d_3\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Conv(%\"add_136\", %\"features.1.2.block.0.weight\"{...}, %\"features.1.2.block.0.bias\"{...}) {group=96, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             35 |  # node_permute_6\n",
              "                   %\"permute_6\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_3\") {perm=(0, 2, 3, 1)}\n",
              "             36 |  # node_layer_norm_3\n",
              "                   %\"layer_norm_3\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_6\", %\"features.1.2.block.2.weight\"{...}, %\"features.1.2.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "             37 |  # node_MatMul_23\n",
              "                   %\"val_31\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_3\", %\"val_30\"{...})\n",
              "             38 |  # node_linear_4\n",
              "                   %\"linear_4\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Add(%\"val_31\", %\"features.1.2.block.3.bias\"{...})\n",
              "             39 |  # node_Div_25\n",
              "                   %\"val_33\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Div(%\"linear_4\", %\"val_6\"{1.4142135381698608})\n",
              "             40 |  # node_Erf_26\n",
              "                   %\"val_34\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Erf(%\"val_33\")\n",
              "             41 |  # node_Add_28\n",
              "                   %\"val_36\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Add(%\"val_34\", %\"val_9\"{1.0})\n",
              "             42 |  # node_Mul_30\n",
              "                   %\"val_38\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_36\")\n",
              "             43 |  # node_gelu_2\n",
              "                   %\"gelu_2\"<FLOAT,[1,56,56,384]> ‚¨ÖÔ∏è ::Mul(%\"linear_4\", %\"val_38\")\n",
              "             44 |  # node_MatMul_32\n",
              "                   %\"val_40\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_2\", %\"val_39\"{...})\n",
              "             45 |  # node_linear_5\n",
              "                   %\"linear_5\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::Add(%\"val_40\", %\"features.1.2.block.5.bias\"{...})\n",
              "             46 |  # node_permute_7\n",
              "                   %\"permute_7\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Transpose(%\"linear_5\") {perm=(0, 3, 1, 2)}\n",
              "             47 |  # node_mul_143\n",
              "                   %\"mul_143\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Mul(%\"features.1.2.layer_scale\"{...}, %\"permute_7\")\n",
              "             48 |  # node_add_182\n",
              "                   %\"add_182\"<FLOAT,[s77,96,56,56]> ‚¨ÖÔ∏è ::Add(%\"mul_143\", %\"add_136\")\n",
              "             49 |  # node_permute_9\n",
              "                   %\"permute_9\"<FLOAT,[s77,56,56,96]> ‚¨ÖÔ∏è ::Transpose(%\"add_182\") {perm=(0, 2, 3, 1)}\n",
              "             50 |  # node_layer_norm_4\n",
              "                   %\"layer_norm_4\"<FLOAT,[1,56,56,96]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_9\", %\"features.2.0.weight\"{...}, %\"features.2.0.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "             51 |  # node_permute_10\n",
              "                   %\"permute_10\"<FLOAT,[1,96,56,56]> ‚¨ÖÔ∏è ::Transpose(%\"layer_norm_4\") {perm=(0, 3, 1, 2)}\n",
              "             52 |  # node_conv2d_4\n",
              "                   %\"conv2d_4\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Conv(%\"permute_10\", %\"features.2.1.weight\"{...}, %\"features.2.1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             53 |  # node_conv2d_5\n",
              "                   %\"conv2d_5\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Conv(%\"conv2d_4\", %\"features.3.0.block.0.weight\"{...}, %\"features.3.0.block.0.bias\"{...}) {group=192, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             54 |  # node_permute_11\n",
              "                   %\"permute_11\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_5\") {perm=(0, 2, 3, 1)}\n",
              "             55 |  # node_layer_norm_5\n",
              "                   %\"layer_norm_5\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_11\", %\"features.3.0.block.2.weight\"{...}, %\"features.3.0.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "             56 |  # node_MatMul_34\n",
              "                   %\"val_46\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_5\", %\"val_45\"{...})\n",
              "             57 |  # node_linear_6\n",
              "                   %\"linear_6\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Add(%\"val_46\", %\"features.3.0.block.3.bias\"{...})\n",
              "             58 |  # node_Div_36\n",
              "                   %\"val_48\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Div(%\"linear_6\", %\"val_6\"{1.4142135381698608})\n",
              "             59 |  # node_Erf_37\n",
              "                   %\"val_49\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Erf(%\"val_48\")\n",
              "             60 |  # node_Add_39\n",
              "                   %\"val_51\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Add(%\"val_49\", %\"val_9\"{1.0})\n",
              "             61 |  # node_Mul_41\n",
              "                   %\"val_53\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_51\")\n",
              "             62 |  # node_gelu_3\n",
              "                   %\"gelu_3\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Mul(%\"linear_6\", %\"val_53\")\n",
              "             63 |  # node_MatMul_43\n",
              "                   %\"val_55\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_3\", %\"val_54\"{...})\n",
              "             64 |  # node_linear_7\n",
              "                   %\"linear_7\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Add(%\"val_55\", %\"features.3.0.block.5.bias\"{...})\n",
              "             65 |  # node_permute_12\n",
              "                   %\"permute_12\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Transpose(%\"linear_7\") {perm=(0, 3, 1, 2)}\n",
              "             66 |  # node_mul_204\n",
              "                   %\"mul_204\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Mul(%\"features.3.0.layer_scale\"{...}, %\"permute_12\")\n",
              "             67 |  # node_add_238\n",
              "                   %\"add_238\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Add(%\"mul_204\", %\"conv2d_4\")\n",
              "             68 |  # node_conv2d_6\n",
              "                   %\"conv2d_6\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Conv(%\"add_238\", %\"features.3.1.block.0.weight\"{...}, %\"features.3.1.block.0.bias\"{...}) {group=192, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             69 |  # node_permute_13\n",
              "                   %\"permute_13\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_6\") {perm=(0, 2, 3, 1)}\n",
              "             70 |  # node_layer_norm_6\n",
              "                   %\"layer_norm_6\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_13\", %\"features.3.1.block.2.weight\"{...}, %\"features.3.1.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "             71 |  # node_MatMul_45\n",
              "                   %\"val_59\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_6\", %\"val_58\"{...})\n",
              "             72 |  # node_linear_8\n",
              "                   %\"linear_8\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Add(%\"val_59\", %\"features.3.1.block.3.bias\"{...})\n",
              "             73 |  # node_Div_47\n",
              "                   %\"val_61\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Div(%\"linear_8\", %\"val_6\"{1.4142135381698608})\n",
              "             74 |  # node_Erf_48\n",
              "                   %\"val_62\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Erf(%\"val_61\")\n",
              "             75 |  # node_Add_50\n",
              "                   %\"val_64\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Add(%\"val_62\", %\"val_9\"{1.0})\n",
              "             76 |  # node_Mul_52\n",
              "                   %\"val_66\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_64\")\n",
              "             77 |  # node_gelu_4\n",
              "                   %\"gelu_4\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Mul(%\"linear_8\", %\"val_66\")\n",
              "             78 |  # node_MatMul_54\n",
              "                   %\"val_68\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_4\", %\"val_67\"{...})\n",
              "             79 |  # node_linear_9\n",
              "                   %\"linear_9\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Add(%\"val_68\", %\"features.3.1.block.5.bias\"{...})\n",
              "             80 |  # node_permute_14\n",
              "                   %\"permute_14\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Transpose(%\"linear_9\") {perm=(0, 3, 1, 2)}\n",
              "             81 |  # node_mul_249\n",
              "                   %\"mul_249\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Mul(%\"features.3.1.layer_scale\"{...}, %\"permute_14\")\n",
              "             82 |  # node_add_277\n",
              "                   %\"add_277\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Add(%\"mul_249\", %\"add_238\")\n",
              "             83 |  # node_conv2d_7\n",
              "                   %\"conv2d_7\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Conv(%\"add_277\", %\"features.3.2.block.0.weight\"{...}, %\"features.3.2.block.0.bias\"{...}) {group=192, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             84 |  # node_permute_15\n",
              "                   %\"permute_15\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_7\") {perm=(0, 2, 3, 1)}\n",
              "             85 |  # node_layer_norm_7\n",
              "                   %\"layer_norm_7\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_15\", %\"features.3.2.block.2.weight\"{...}, %\"features.3.2.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "             86 |  # node_MatMul_56\n",
              "                   %\"val_72\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_7\", %\"val_71\"{...})\n",
              "             87 |  # node_linear_10\n",
              "                   %\"linear_10\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Add(%\"val_72\", %\"features.3.2.block.3.bias\"{...})\n",
              "             88 |  # node_Div_58\n",
              "                   %\"val_74\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Div(%\"linear_10\", %\"val_6\"{1.4142135381698608})\n",
              "             89 |  # node_Erf_59\n",
              "                   %\"val_75\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Erf(%\"val_74\")\n",
              "             90 |  # node_Add_61\n",
              "                   %\"val_77\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Add(%\"val_75\", %\"val_9\"{1.0})\n",
              "             91 |  # node_Mul_63\n",
              "                   %\"val_79\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_77\")\n",
              "             92 |  # node_gelu_5\n",
              "                   %\"gelu_5\"<FLOAT,[1,28,28,768]> ‚¨ÖÔ∏è ::Mul(%\"linear_10\", %\"val_79\")\n",
              "             93 |  # node_MatMul_65\n",
              "                   %\"val_81\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_5\", %\"val_80\"{...})\n",
              "             94 |  # node_linear_11\n",
              "                   %\"linear_11\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Add(%\"val_81\", %\"features.3.2.block.5.bias\"{...})\n",
              "             95 |  # node_permute_16\n",
              "                   %\"permute_16\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Transpose(%\"linear_11\") {perm=(0, 3, 1, 2)}\n",
              "             96 |  # node_mul_294\n",
              "                   %\"mul_294\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Mul(%\"features.3.2.layer_scale\"{...}, %\"permute_16\")\n",
              "             97 |  # node_add_316\n",
              "                   %\"add_316\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Add(%\"mul_294\", %\"add_277\")\n",
              "             98 |  # node_permute_18\n",
              "                   %\"permute_18\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::Transpose(%\"add_316\") {perm=(0, 2, 3, 1)}\n",
              "             99 |  # node_layer_norm_8\n",
              "                   %\"layer_norm_8\"<FLOAT,[1,28,28,192]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_18\", %\"features.4.0.weight\"{...}, %\"features.4.0.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            100 |  # node_permute_19\n",
              "                   %\"permute_19\"<FLOAT,[1,192,28,28]> ‚¨ÖÔ∏è ::Transpose(%\"layer_norm_8\") {perm=(0, 3, 1, 2)}\n",
              "            101 |  # node_conv2d_8\n",
              "                   %\"conv2d_8\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"permute_19\", %\"features.4.1.weight\"{...}, %\"features.4.1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            102 |  # node_conv2d_9\n",
              "                   %\"conv2d_9\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"conv2d_8\", %\"features.5.0.block.0.weight\"{...}, %\"features.5.0.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            103 |  # node_permute_20\n",
              "                   %\"permute_20\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_9\") {perm=(0, 2, 3, 1)}\n",
              "            104 |  # node_layer_norm_9\n",
              "                   %\"layer_norm_9\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_20\", %\"features.5.0.block.2.weight\"{...}, %\"features.5.0.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            105 |  # node_MatMul_67\n",
              "                   %\"val_87\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_9\", %\"val_86\"{...})\n",
              "            106 |  # node_linear_12\n",
              "                   %\"linear_12\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_87\", %\"features.5.0.block.3.bias\"{...})\n",
              "            107 |  # node_Div_69\n",
              "                   %\"val_89\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_12\", %\"val_6\"{1.4142135381698608})\n",
              "            108 |  # node_Erf_70\n",
              "                   %\"val_90\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_89\")\n",
              "            109 |  # node_Add_72\n",
              "                   %\"val_92\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_90\", %\"val_9\"{1.0})\n",
              "            110 |  # node_Mul_74\n",
              "                   %\"val_94\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_92\")\n",
              "            111 |  # node_gelu_6\n",
              "                   %\"gelu_6\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_12\", %\"val_94\")\n",
              "            112 |  # node_MatMul_76\n",
              "                   %\"val_96\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_6\", %\"val_95\"{...})\n",
              "            113 |  # node_linear_13\n",
              "                   %\"linear_13\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_96\", %\"features.5.0.block.5.bias\"{...})\n",
              "            114 |  # node_permute_21\n",
              "                   %\"permute_21\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_13\") {perm=(0, 3, 1, 2)}\n",
              "            115 |  # node_mul_355\n",
              "                   %\"mul_355\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.0.layer_scale\"{...}, %\"permute_21\")\n",
              "            116 |  # node_add_369\n",
              "                   %\"add_369\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_355\", %\"conv2d_8\")\n",
              "            117 |  # node_conv2d_10\n",
              "                   %\"conv2d_10\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_369\", %\"features.5.1.block.0.weight\"{...}, %\"features.5.1.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            118 |  # node_permute_22\n",
              "                   %\"permute_22\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_10\") {perm=(0, 2, 3, 1)}\n",
              "            119 |  # node_layer_norm_10\n",
              "                   %\"layer_norm_10\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_22\", %\"features.5.1.block.2.weight\"{...}, %\"features.5.1.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            120 |  # node_MatMul_78\n",
              "                   %\"val_100\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_10\", %\"val_99\"{...})\n",
              "            121 |  # node_linear_14\n",
              "                   %\"linear_14\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_100\", %\"features.5.1.block.3.bias\"{...})\n",
              "            122 |  # node_Div_80\n",
              "                   %\"val_102\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_14\", %\"val_6\"{1.4142135381698608})\n",
              "            123 |  # node_Erf_81\n",
              "                   %\"val_103\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_102\")\n",
              "            124 |  # node_Add_83\n",
              "                   %\"val_105\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_103\", %\"val_9\"{1.0})\n",
              "            125 |  # node_Mul_85\n",
              "                   %\"val_107\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_105\")\n",
              "            126 |  # node_gelu_7\n",
              "                   %\"gelu_7\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_14\", %\"val_107\")\n",
              "            127 |  # node_MatMul_87\n",
              "                   %\"val_109\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_7\", %\"val_108\"{...})\n",
              "            128 |  # node_linear_15\n",
              "                   %\"linear_15\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_109\", %\"features.5.1.block.5.bias\"{...})\n",
              "            129 |  # node_permute_23\n",
              "                   %\"permute_23\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_15\") {perm=(0, 3, 1, 2)}\n",
              "            130 |  # node_mul_400\n",
              "                   %\"mul_400\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.1.layer_scale\"{...}, %\"permute_23\")\n",
              "            131 |  # node_add_408\n",
              "                   %\"add_408\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_400\", %\"add_369\")\n",
              "            132 |  # node_conv2d_11\n",
              "                   %\"conv2d_11\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_408\", %\"features.5.2.block.0.weight\"{...}, %\"features.5.2.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            133 |  # node_permute_24\n",
              "                   %\"permute_24\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_11\") {perm=(0, 2, 3, 1)}\n",
              "            134 |  # node_layer_norm_11\n",
              "                   %\"layer_norm_11\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_24\", %\"features.5.2.block.2.weight\"{...}, %\"features.5.2.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            135 |  # node_MatMul_89\n",
              "                   %\"val_113\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_11\", %\"val_112\"{...})\n",
              "            136 |  # node_linear_16\n",
              "                   %\"linear_16\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_113\", %\"features.5.2.block.3.bias\"{...})\n",
              "            137 |  # node_Div_91\n",
              "                   %\"val_115\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_16\", %\"val_6\"{1.4142135381698608})\n",
              "            138 |  # node_Erf_92\n",
              "                   %\"val_116\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_115\")\n",
              "            139 |  # node_Add_94\n",
              "                   %\"val_118\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_116\", %\"val_9\"{1.0})\n",
              "            140 |  # node_Mul_96\n",
              "                   %\"val_120\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_118\")\n",
              "            141 |  # node_gelu_8\n",
              "                   %\"gelu_8\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_16\", %\"val_120\")\n",
              "            142 |  # node_MatMul_98\n",
              "                   %\"val_122\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_8\", %\"val_121\"{...})\n",
              "            143 |  # node_linear_17\n",
              "                   %\"linear_17\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_122\", %\"features.5.2.block.5.bias\"{...})\n",
              "            144 |  # node_permute_25\n",
              "                   %\"permute_25\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_17\") {perm=(0, 3, 1, 2)}\n",
              "            145 |  # node_mul_445\n",
              "                   %\"mul_445\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.2.layer_scale\"{...}, %\"permute_25\")\n",
              "            146 |  # node_add_447\n",
              "                   %\"add_447\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_445\", %\"add_408\")\n",
              "            147 |  # node_conv2d_12\n",
              "                   %\"conv2d_12\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_447\", %\"features.5.3.block.0.weight\"{...}, %\"features.5.3.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            148 |  # node_permute_26\n",
              "                   %\"permute_26\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_12\") {perm=(0, 2, 3, 1)}\n",
              "            149 |  # node_layer_norm_12\n",
              "                   %\"layer_norm_12\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_26\", %\"features.5.3.block.2.weight\"{...}, %\"features.5.3.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            150 |  # node_MatMul_100\n",
              "                   %\"val_126\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_12\", %\"val_125\"{...})\n",
              "            151 |  # node_linear_18\n",
              "                   %\"linear_18\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_126\", %\"features.5.3.block.3.bias\"{...})\n",
              "            152 |  # node_Div_102\n",
              "                   %\"val_128\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_18\", %\"val_6\"{1.4142135381698608})\n",
              "            153 |  # node_Erf_103\n",
              "                   %\"val_129\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_128\")\n",
              "            154 |  # node_Add_105\n",
              "                   %\"val_131\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_129\", %\"val_9\"{1.0})\n",
              "            155 |  # node_Mul_107\n",
              "                   %\"val_133\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_131\")\n",
              "            156 |  # node_gelu_9\n",
              "                   %\"gelu_9\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_18\", %\"val_133\")\n",
              "            157 |  # node_MatMul_109\n",
              "                   %\"val_135\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_9\", %\"val_134\"{...})\n",
              "            158 |  # node_linear_19\n",
              "                   %\"linear_19\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_135\", %\"features.5.3.block.5.bias\"{...})\n",
              "            159 |  # node_permute_27\n",
              "                   %\"permute_27\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_19\") {perm=(0, 3, 1, 2)}\n",
              "            160 |  # node_mul_490\n",
              "                   %\"mul_490\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.3.layer_scale\"{...}, %\"permute_27\")\n",
              "            161 |  # node_add_486\n",
              "                   %\"add_486\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_490\", %\"add_447\")\n",
              "            162 |  # node_conv2d_13\n",
              "                   %\"conv2d_13\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_486\", %\"features.5.4.block.0.weight\"{...}, %\"features.5.4.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            163 |  # node_permute_28\n",
              "                   %\"permute_28\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_13\") {perm=(0, 2, 3, 1)}\n",
              "            164 |  # node_layer_norm_13\n",
              "                   %\"layer_norm_13\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_28\", %\"features.5.4.block.2.weight\"{...}, %\"features.5.4.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            165 |  # node_MatMul_111\n",
              "                   %\"val_139\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_13\", %\"val_138\"{...})\n",
              "            166 |  # node_linear_20\n",
              "                   %\"linear_20\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_139\", %\"features.5.4.block.3.bias\"{...})\n",
              "            167 |  # node_Div_113\n",
              "                   %\"val_141\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_20\", %\"val_6\"{1.4142135381698608})\n",
              "            168 |  # node_Erf_114\n",
              "                   %\"val_142\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_141\")\n",
              "            169 |  # node_Add_116\n",
              "                   %\"val_144\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_142\", %\"val_9\"{1.0})\n",
              "            170 |  # node_Mul_118\n",
              "                   %\"val_146\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_144\")\n",
              "            171 |  # node_gelu_10\n",
              "                   %\"gelu_10\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_20\", %\"val_146\")\n",
              "            172 |  # node_MatMul_120\n",
              "                   %\"val_148\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_10\", %\"val_147\"{...})\n",
              "            173 |  # node_linear_21\n",
              "                   %\"linear_21\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_148\", %\"features.5.4.block.5.bias\"{...})\n",
              "            174 |  # node_permute_29\n",
              "                   %\"permute_29\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_21\") {perm=(0, 3, 1, 2)}\n",
              "            175 |  # node_mul_535\n",
              "                   %\"mul_535\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.4.layer_scale\"{...}, %\"permute_29\")\n",
              "            176 |  # node_add_525\n",
              "                   %\"add_525\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_535\", %\"add_486\")\n",
              "            177 |  # node_conv2d_14\n",
              "                   %\"conv2d_14\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_525\", %\"features.5.5.block.0.weight\"{...}, %\"features.5.5.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            178 |  # node_permute_30\n",
              "                   %\"permute_30\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_14\") {perm=(0, 2, 3, 1)}\n",
              "            179 |  # node_layer_norm_14\n",
              "                   %\"layer_norm_14\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_30\", %\"features.5.5.block.2.weight\"{...}, %\"features.5.5.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            180 |  # node_MatMul_122\n",
              "                   %\"val_152\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_14\", %\"val_151\"{...})\n",
              "            181 |  # node_linear_22\n",
              "                   %\"linear_22\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_152\", %\"features.5.5.block.3.bias\"{...})\n",
              "            182 |  # node_Div_124\n",
              "                   %\"val_154\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_22\", %\"val_6\"{1.4142135381698608})\n",
              "            183 |  # node_Erf_125\n",
              "                   %\"val_155\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_154\")\n",
              "            184 |  # node_Add_127\n",
              "                   %\"val_157\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_155\", %\"val_9\"{1.0})\n",
              "            185 |  # node_Mul_129\n",
              "                   %\"val_159\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_157\")\n",
              "            186 |  # node_gelu_11\n",
              "                   %\"gelu_11\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_22\", %\"val_159\")\n",
              "            187 |  # node_MatMul_131\n",
              "                   %\"val_161\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_11\", %\"val_160\"{...})\n",
              "            188 |  # node_linear_23\n",
              "                   %\"linear_23\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_161\", %\"features.5.5.block.5.bias\"{...})\n",
              "            189 |  # node_permute_31\n",
              "                   %\"permute_31\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_23\") {perm=(0, 3, 1, 2)}\n",
              "            190 |  # node_mul_580\n",
              "                   %\"mul_580\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.5.layer_scale\"{...}, %\"permute_31\")\n",
              "            191 |  # node_add_564\n",
              "                   %\"add_564\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_580\", %\"add_525\")\n",
              "            192 |  # node_conv2d_15\n",
              "                   %\"conv2d_15\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_564\", %\"features.5.6.block.0.weight\"{...}, %\"features.5.6.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            193 |  # node_permute_32\n",
              "                   %\"permute_32\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_15\") {perm=(0, 2, 3, 1)}\n",
              "            194 |  # node_layer_norm_15\n",
              "                   %\"layer_norm_15\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_32\", %\"features.5.6.block.2.weight\"{...}, %\"features.5.6.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            195 |  # node_MatMul_133\n",
              "                   %\"val_165\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_15\", %\"val_164\"{...})\n",
              "            196 |  # node_linear_24\n",
              "                   %\"linear_24\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_165\", %\"features.5.6.block.3.bias\"{...})\n",
              "            197 |  # node_Div_135\n",
              "                   %\"val_167\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_24\", %\"val_6\"{1.4142135381698608})\n",
              "            198 |  # node_Erf_136\n",
              "                   %\"val_168\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_167\")\n",
              "            199 |  # node_Add_138\n",
              "                   %\"val_170\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_168\", %\"val_9\"{1.0})\n",
              "            200 |  # node_Mul_140\n",
              "                   %\"val_172\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_170\")\n",
              "            201 |  # node_gelu_12\n",
              "                   %\"gelu_12\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_24\", %\"val_172\")\n",
              "            202 |  # node_MatMul_142\n",
              "                   %\"val_174\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_12\", %\"val_173\"{...})\n",
              "            203 |  # node_linear_25\n",
              "                   %\"linear_25\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_174\", %\"features.5.6.block.5.bias\"{...})\n",
              "            204 |  # node_permute_33\n",
              "                   %\"permute_33\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_25\") {perm=(0, 3, 1, 2)}\n",
              "            205 |  # node_mul_625\n",
              "                   %\"mul_625\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.6.layer_scale\"{...}, %\"permute_33\")\n",
              "            206 |  # node_add_603\n",
              "                   %\"add_603\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_625\", %\"add_564\")\n",
              "            207 |  # node_conv2d_16\n",
              "                   %\"conv2d_16\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_603\", %\"features.5.7.block.0.weight\"{...}, %\"features.5.7.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            208 |  # node_permute_34\n",
              "                   %\"permute_34\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_16\") {perm=(0, 2, 3, 1)}\n",
              "            209 |  # node_layer_norm_16\n",
              "                   %\"layer_norm_16\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_34\", %\"features.5.7.block.2.weight\"{...}, %\"features.5.7.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            210 |  # node_MatMul_144\n",
              "                   %\"val_178\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_16\", %\"val_177\"{...})\n",
              "            211 |  # node_linear_26\n",
              "                   %\"linear_26\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_178\", %\"features.5.7.block.3.bias\"{...})\n",
              "            212 |  # node_Div_146\n",
              "                   %\"val_180\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_26\", %\"val_6\"{1.4142135381698608})\n",
              "            213 |  # node_Erf_147\n",
              "                   %\"val_181\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_180\")\n",
              "            214 |  # node_Add_149\n",
              "                   %\"val_183\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_181\", %\"val_9\"{1.0})\n",
              "            215 |  # node_Mul_151\n",
              "                   %\"val_185\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_183\")\n",
              "            216 |  # node_gelu_13\n",
              "                   %\"gelu_13\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_26\", %\"val_185\")\n",
              "            217 |  # node_MatMul_153\n",
              "                   %\"val_187\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_13\", %\"val_186\"{...})\n",
              "            218 |  # node_linear_27\n",
              "                   %\"linear_27\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_187\", %\"features.5.7.block.5.bias\"{...})\n",
              "            219 |  # node_permute_35\n",
              "                   %\"permute_35\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_27\") {perm=(0, 3, 1, 2)}\n",
              "            220 |  # node_mul_670\n",
              "                   %\"mul_670\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.7.layer_scale\"{...}, %\"permute_35\")\n",
              "            221 |  # node_add_642\n",
              "                   %\"add_642\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_670\", %\"add_603\")\n",
              "            222 |  # node_conv2d_17\n",
              "                   %\"conv2d_17\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Conv(%\"add_642\", %\"features.5.8.block.0.weight\"{...}, %\"features.5.8.block.0.bias\"{...}) {group=384, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            223 |  # node_permute_36\n",
              "                   %\"permute_36\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_17\") {perm=(0, 2, 3, 1)}\n",
              "            224 |  # node_layer_norm_17\n",
              "                   %\"layer_norm_17\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_36\", %\"features.5.8.block.2.weight\"{...}, %\"features.5.8.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            225 |  # node_MatMul_155\n",
              "                   %\"val_191\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_17\", %\"val_190\"{...})\n",
              "            226 |  # node_linear_28\n",
              "                   %\"linear_28\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_191\", %\"features.5.8.block.3.bias\"{...})\n",
              "            227 |  # node_Div_157\n",
              "                   %\"val_193\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Div(%\"linear_28\", %\"val_6\"{1.4142135381698608})\n",
              "            228 |  # node_Erf_158\n",
              "                   %\"val_194\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Erf(%\"val_193\")\n",
              "            229 |  # node_Add_160\n",
              "                   %\"val_196\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Add(%\"val_194\", %\"val_9\"{1.0})\n",
              "            230 |  # node_Mul_162\n",
              "                   %\"val_198\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_196\")\n",
              "            231 |  # node_gelu_14\n",
              "                   %\"gelu_14\"<FLOAT,[1,14,14,1536]> ‚¨ÖÔ∏è ::Mul(%\"linear_28\", %\"val_198\")\n",
              "            232 |  # node_MatMul_164\n",
              "                   %\"val_200\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_14\", %\"val_199\"{...})\n",
              "            233 |  # node_linear_29\n",
              "                   %\"linear_29\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Add(%\"val_200\", %\"features.5.8.block.5.bias\"{...})\n",
              "            234 |  # node_permute_37\n",
              "                   %\"permute_37\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"linear_29\") {perm=(0, 3, 1, 2)}\n",
              "            235 |  # node_mul_715\n",
              "                   %\"mul_715\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Mul(%\"features.5.8.layer_scale\"{...}, %\"permute_37\")\n",
              "            236 |  # node_add_681\n",
              "                   %\"add_681\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Add(%\"mul_715\", %\"add_642\")\n",
              "            237 |  # node_permute_39\n",
              "                   %\"permute_39\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::Transpose(%\"add_681\") {perm=(0, 2, 3, 1)}\n",
              "            238 |  # node_layer_norm_18\n",
              "                   %\"layer_norm_18\"<FLOAT,[1,14,14,384]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_39\", %\"features.6.0.weight\"{...}, %\"features.6.0.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            239 |  # node_permute_40\n",
              "                   %\"permute_40\"<FLOAT,[1,384,14,14]> ‚¨ÖÔ∏è ::Transpose(%\"layer_norm_18\") {perm=(0, 3, 1, 2)}\n",
              "            240 |  # node_conv2d_18\n",
              "                   %\"conv2d_18\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Conv(%\"permute_40\", %\"features.6.1.weight\"{...}, %\"features.6.1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            241 |  # node_conv2d_19\n",
              "                   %\"conv2d_19\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Conv(%\"conv2d_18\", %\"features.7.0.block.0.weight\"{...}, %\"features.7.0.block.0.bias\"{...}) {group=768, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            242 |  # node_permute_41\n",
              "                   %\"permute_41\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_19\") {perm=(0, 2, 3, 1)}\n",
              "            243 |  # node_layer_norm_19\n",
              "                   %\"layer_norm_19\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_41\", %\"features.7.0.block.2.weight\"{...}, %\"features.7.0.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            244 |  # node_MatMul_166\n",
              "                   %\"val_206\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_19\", %\"val_205\"{...})\n",
              "            245 |  # node_linear_30\n",
              "                   %\"linear_30\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Add(%\"val_206\", %\"features.7.0.block.3.bias\"{...})\n",
              "            246 |  # node_Div_168\n",
              "                   %\"val_208\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Div(%\"linear_30\", %\"val_6\"{1.4142135381698608})\n",
              "            247 |  # node_Erf_169\n",
              "                   %\"val_209\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Erf(%\"val_208\")\n",
              "            248 |  # node_Add_171\n",
              "                   %\"val_211\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Add(%\"val_209\", %\"val_9\"{1.0})\n",
              "            249 |  # node_Mul_173\n",
              "                   %\"val_213\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_211\")\n",
              "            250 |  # node_gelu_15\n",
              "                   %\"gelu_15\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Mul(%\"linear_30\", %\"val_213\")\n",
              "            251 |  # node_MatMul_175\n",
              "                   %\"val_215\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_15\", %\"val_214\"{...})\n",
              "            252 |  # node_linear_31\n",
              "                   %\"linear_31\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::Add(%\"val_215\", %\"features.7.0.block.5.bias\"{...})\n",
              "            253 |  # node_permute_42\n",
              "                   %\"permute_42\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Transpose(%\"linear_31\") {perm=(0, 3, 1, 2)}\n",
              "            254 |  # node_mul_776\n",
              "                   %\"mul_776\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Mul(%\"features.7.0.layer_scale\"{...}, %\"permute_42\")\n",
              "            255 |  # node_add_734\n",
              "                   %\"add_734\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Add(%\"mul_776\", %\"conv2d_18\")\n",
              "            256 |  # node_conv2d_20\n",
              "                   %\"conv2d_20\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Conv(%\"add_734\", %\"features.7.1.block.0.weight\"{...}, %\"features.7.1.block.0.bias\"{...}) {group=768, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            257 |  # node_permute_43\n",
              "                   %\"permute_43\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_20\") {perm=(0, 2, 3, 1)}\n",
              "            258 |  # node_layer_norm_20\n",
              "                   %\"layer_norm_20\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_43\", %\"features.7.1.block.2.weight\"{...}, %\"features.7.1.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            259 |  # node_MatMul_177\n",
              "                   %\"val_219\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_20\", %\"val_218\"{...})\n",
              "            260 |  # node_linear_32\n",
              "                   %\"linear_32\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Add(%\"val_219\", %\"features.7.1.block.3.bias\"{...})\n",
              "            261 |  # node_Div_179\n",
              "                   %\"val_221\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Div(%\"linear_32\", %\"val_6\"{1.4142135381698608})\n",
              "            262 |  # node_Erf_180\n",
              "                   %\"val_222\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Erf(%\"val_221\")\n",
              "            263 |  # node_Add_182\n",
              "                   %\"val_224\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Add(%\"val_222\", %\"val_9\"{1.0})\n",
              "            264 |  # node_Mul_184\n",
              "                   %\"val_226\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_224\")\n",
              "            265 |  # node_gelu_16\n",
              "                   %\"gelu_16\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Mul(%\"linear_32\", %\"val_226\")\n",
              "            266 |  # node_MatMul_186\n",
              "                   %\"val_228\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_16\", %\"val_227\"{...})\n",
              "            267 |  # node_linear_33\n",
              "                   %\"linear_33\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::Add(%\"val_228\", %\"features.7.1.block.5.bias\"{...})\n",
              "            268 |  # node_permute_44\n",
              "                   %\"permute_44\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Transpose(%\"linear_33\") {perm=(0, 3, 1, 2)}\n",
              "            269 |  # node_mul_821\n",
              "                   %\"mul_821\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Mul(%\"features.7.1.layer_scale\"{...}, %\"permute_44\")\n",
              "            270 |  # node_add_773\n",
              "                   %\"add_773\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Add(%\"mul_821\", %\"add_734\")\n",
              "            271 |  # node_conv2d_21\n",
              "                   %\"conv2d_21\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Conv(%\"add_773\", %\"features.7.2.block.0.weight\"{...}, %\"features.7.2.block.0.bias\"{...}) {group=768, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            272 |  # node_permute_45\n",
              "                   %\"permute_45\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::Transpose(%\"conv2d_21\") {perm=(0, 2, 3, 1)}\n",
              "            273 |  # node_layer_norm_21\n",
              "                   %\"layer_norm_21\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::LayerNormalization(%\"permute_45\", %\"features.7.2.block.2.weight\"{...}, %\"features.7.2.block.2.bias\"{...}) {stash_type=1, epsilon=1e-06, axis=-1}\n",
              "            274 |  # node_MatMul_188\n",
              "                   %\"val_232\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::MatMul(%\"layer_norm_21\", %\"val_231\"{...})\n",
              "            275 |  # node_linear_34\n",
              "                   %\"linear_34\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Add(%\"val_232\", %\"features.7.2.block.3.bias\"{...})\n",
              "            276 |  # node_Div_190\n",
              "                   %\"val_234\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Div(%\"linear_34\", %\"val_6\"{1.4142135381698608})\n",
              "            277 |  # node_Erf_191\n",
              "                   %\"val_235\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Erf(%\"val_234\")\n",
              "            278 |  # node_Add_193\n",
              "                   %\"val_237\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Add(%\"val_235\", %\"val_9\"{1.0})\n",
              "            279 |  # node_Mul_195\n",
              "                   %\"val_239\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Mul(%\"val_11\"{0.5}, %\"val_237\")\n",
              "            280 |  # node_gelu_17\n",
              "                   %\"gelu_17\"<FLOAT,[1,7,7,3072]> ‚¨ÖÔ∏è ::Mul(%\"linear_34\", %\"val_239\")\n",
              "            281 |  # node_MatMul_197\n",
              "                   %\"val_241\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::MatMul(%\"gelu_17\", %\"val_240\"{...})\n",
              "            282 |  # node_linear_35\n",
              "                   %\"linear_35\"<FLOAT,[1,7,7,768]> ‚¨ÖÔ∏è ::Add(%\"val_241\", %\"features.7.2.block.5.bias\"{...})\n",
              "            283 |  # node_permute_46\n",
              "                   %\"permute_46\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Transpose(%\"linear_35\") {perm=(0, 3, 1, 2)}\n",
              "            284 |  # node_mul_866\n",
              "                   %\"mul_866\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Mul(%\"features.7.2.layer_scale\"{...}, %\"permute_46\")\n",
              "            285 |  # node_add_812\n",
              "                   %\"add_812\"<FLOAT,[1,768,7,7]> ‚¨ÖÔ∏è ::Add(%\"mul_866\", %\"add_773\")\n",
              "            286 |  # node_mean\n",
              "                   %\"mean\"<FLOAT,[1,768,1,1]> ‚¨ÖÔ∏è ::ReduceMean(%\"add_812\", %\"val_244\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
              "            287 |  # n4\n",
              "                   %\"one_seq\"<Sequence(Tensor(FLOAT)),?> ‚¨ÖÔ∏è ::SequenceEmpty()\n",
              "            288 |  # n6_2\n",
              "                   %\"one_seq_16\"<?,?>, %\"indices_17\"<?,?> ‚¨ÖÔ∏è ::Loop(%\"rank_0\"{4}, None, %\"one_seq\", %\"indices\"{0}) {body=\n",
              "                       graph(\n",
              "                           name=loop_body,\n",
              "                           inputs=(\n",
              "                               %\"i\"<INT64,[]>,\n",
              "                               %\"cond_in\"<BOOL,[]>,\n",
              "                               %\"one_seq_1\"<?,?>,\n",
              "                               %\"indices_2\"<?,?>\n",
              "                           ),\n",
              "                           outputs=(\n",
              "                               %\"cond_out\"<BOOL,[]>,\n",
              "                               %\"one_seq_15\"<?,?>,\n",
              "                               %\"indices_13\"<?,?>\n",
              "                           ),\n",
              "                       ) {\n",
              "                            0 |  # n2_2\n",
              "                                 %\"tmp\"<INT64,[]> ‚¨ÖÔ∏è ::Sub(%\"rank_0\"{4}, %\"i\")\n",
              "                            1 |  # n5_2\n",
              "                                 %\"j\"<INT64,[]> ‚¨ÖÔ∏è ::Sub(%\"tmp\", %\"int64_1_cast\"{1})\n",
              "                            2 |  # n6\n",
              "                                 %\"j_tensor\"<INT64,[1]> ‚¨ÖÔ∏è ::Reshape(%\"j\", %\"neg_1\"{[-1]})\n",
              "                            3 |  # n7\n",
              "                                 %\"size_dim_j\"<INT64,[1]> ‚¨ÖÔ∏è ::Gather(%\"val_245\"{[1, 768, 1, 1]}, %\"j_tensor\") {axis=0}\n",
              "                            4 |  # n8\n",
              "                                 %\"size_after_j\"<INT64,[None]> ‚¨ÖÔ∏è ::Slice(%\"val_245\"{[1, 768, 1, 1]}, %\"j_tensor\", %\"rank_tensor\"{[4]})\n",
              "                            5 |  # n9\n",
              "                                 %\"stride_dim_j\"<INT64,[1]> ‚¨ÖÔ∏è ::Gather(%\"val_246\"{[768, 1, 768, 768]}, %\"j_tensor\") {axis=0}\n",
              "                            6 |  # n10\n",
              "                                 %\"indices_4\"<?,?> ‚¨ÖÔ∏è ::Expand(%\"indices_2\", %\"size_after_j\")\n",
              "                            7 |  # n15\n",
              "                                 %\"tmp_6\"<INT64,[None]> ‚¨ÖÔ∏è ::Range(%\"indices\"{0}, %\"size_dim_j\", %\"int64_1_cast\"{1})\n",
              "                            8 |  # n16\n",
              "                                 %\"add_value\"<INT64,[None]> ‚¨ÖÔ∏è ::Mul(%\"tmp_6\", %\"stride_dim_j\")\n",
              "                            9 |  # n19\n",
              "                                 %\"cond\"<BOOL,[]> ‚¨ÖÔ∏è ::Equal(%\"i\", %\"indices\"{0})\n",
              "                           10 |  # n20\n",
              "                                 %\"shape_11\"<?,?> ‚¨ÖÔ∏è ::If(%\"cond\") {then_branch=\n",
              "                                     graph(\n",
              "                                         name=thenGraph_39,\n",
              "                                         inputs=(\n",
              "\n",
              "                                         ),\n",
              "                                         outputs=(\n",
              "                                             %\"shape\"<INT64,[1]>\n",
              "                                         ),\n",
              "                                     ) {\n",
              "                                         0 |  # n0_3\n",
              "                                              %\"shape\"<INT64,[1]> ‚¨ÖÔ∏è ::Identity(%\"size_dim_j\")\n",
              "                                         return %\"shape\"<INT64,[1]>\n",
              "                                     }, else_branch=\n",
              "                                     graph(\n",
              "                                         name=elseGraph_39,\n",
              "                                         inputs=(\n",
              "\n",
              "                                         ),\n",
              "                                         outputs=(\n",
              "                                             %\"shape_10\"<INT64,?>\n",
              "                                         ),\n",
              "                                     ) {\n",
              "                                         0 |  # n0_4\n",
              "                                              %\"ones\"<?,?> ‚¨ÖÔ∏è ::ConcatFromSequence(%\"one_seq_1\") {axis=0}\n",
              "                                         1 |  # n1_3\n",
              "                                              %\"tmp_8\"<FLOAT,[1]> ‚¨ÖÔ∏è ::Cast(%\"size_dim_j\") {to=1}\n",
              "                                         2 |  # n2_3\n",
              "                                              %\"shape_9\"<?,?> ‚¨ÖÔ∏è ::Concat(%\"tmp_8\", %\"ones\") {axis=0}\n",
              "                                         3 |  # n3_3\n",
              "                                              %\"shape_10\"<INT64,?> ‚¨ÖÔ∏è ::Cast(%\"shape_9\") {to=7}\n",
              "                                         return %\"shape_10\"<INT64,?>\n",
              "                                     }}\n",
              "                           11 |  # n21\n",
              "                                 %\"add_value_12\"<?,?> ‚¨ÖÔ∏è ::Reshape(%\"add_value\", %\"shape_11\")\n",
              "                           12 |  # n22\n",
              "                                 %\"indices_13\"<?,?> ‚¨ÖÔ∏è ::Add(%\"indices_4\", %\"add_value_12\")\n",
              "                           13 |  # n24\n",
              "                                 %\"one_seq_15\"<?,?> ‚¨ÖÔ∏è ::SequenceInsert(%\"one_seq_1\", %\"tmp_14\"{[1.0]})\n",
              "                           14 |  # n25\n",
              "                                 %\"cond_out\"<BOOL,[]> ‚¨ÖÔ∏è ::Identity(%\"cond_in\")\n",
              "                           return %\"cond_out\"<BOOL,[]>, %\"one_seq_15\"<?,?>, %\"indices_13\"<?,?>\n",
              "                       }}\n",
              "            289 |  # n8_2\n",
              "                   %\"self_flatten\"<FLOAT,[768]> ‚¨ÖÔ∏è ::Reshape(%\"mean\", %\"neg_1\"{[-1]})\n",
              "            290 |  # n10_2\n",
              "                   %\"storage_offset_cast\"<?,?> ‚¨ÖÔ∏è ::CastLike(%\"indices\"{0}, %\"indices_17\")\n",
              "            291 |  # n11_2\n",
              "                   %\"indices_19\"<?,?> ‚¨ÖÔ∏è ::Add(%\"indices_17\", %\"storage_offset_cast\")\n",
              "            292 |  # n12_2\n",
              "                   %\"as_strided\"<FLOAT,[1,768,1,1]> ‚¨ÖÔ∏è ::Gather(%\"self_flatten\", %\"indices_19\")\n",
              "            293 |  # node_view\n",
              "                   %\"view\"<FLOAT,[1,768]> ‚¨ÖÔ∏è ::Reshape(%\"as_strided\", %\"val_250\"{[1, 768]}) {allowzero=1}\n",
              "            294 |  # node_layer_norm_22\n",
              "                   %\"layer_norm_22\"<FLOAT,[1,768]> ‚¨ÖÔ∏è ::LayerNormalization(%\"view\", %\"norm.weight\"{...}, %\"norm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            295 |  # node_linear_36\n",
              "                   %\"output\"<FLOAT,[1,10]> ‚¨ÖÔ∏è ::Gemm(%\"layer_norm_22\", %\"classifier.weight\"{...}, %\"classifier.bias\"{[-0.010878887958824635, -0.02814115211367607, 0.018550876528024673, -0.007955081760883331, -0.010361481457948685, -0.035075895488262177, -0.01602650247514248, -0.007114824838936329, -0.02173069305717945, 0.0017036674544215202]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            return %\"output\"<FLOAT,[1,10]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_features_0_0_weight: \"f32[96, 3, 4, 4]\", p_features_0_0_bias: \"f32[96]\", p_features_0_1_weight: \"f32[96]\", p_features_0_1_bias: \"f32[96]\", p_features_1_0_layer_scale: \"f32[96, 1, 1]\", p_features_1_0_block_0_weight: \"f32[96, 1, 7, 7]\", p_features_1_0_block_0_bias: \"f32[96]\", p_features_1_0_block_2_weight: \"f32[96]\", p_features_1_0_block_2_bias: \"f32[96]\", p_features_1_0_block_3_weight: \"f32[384, 96]\", p_features_1_0_block_3_bias: \"f32[384]\", p_features_1_0_block_5_weight: \"f32[96, 384]\", p_features_1_0_block_5_bias: \"f32[96]\", p_features_1_1_layer_scale: \"f32[96, 1, 1]\", p_features_1_1_block_0_weight: \"f32[96, 1, 7, 7]\", p_features_1_1_block_0_bias: \"f32[96]\", p_features_1_1_block_2_weight: \"f32[96]\", p_features_1_1_block_2_bias: \"f32[96]\", p_features_1_1_block_3_weight: \"f32[384, 96]\", p_features_1_1_block_3_bias: \"f32[384]\", p_features_1_1_block_5_weight: \"f32[96, 384]\", p_features_1_1_block_5_bias: \"f32[96]\", p_features_1_2_layer_scale: \"f32[96, 1, 1]\", p_features_1_2_block_0_weight: \"f32[96, 1, 7, 7]\", p_features_1_2_block_0_bias: \"f32[96]\", p_features_1_2_block_2_weight: \"f32[96]\", p_features_1_2_block_2_bias: \"f32[96]\", p_features_1_2_block_3_weight: \"f32[384, 96]\", p_features_1_2_block_3_bias: \"f32[384]\", p_features_1_2_block_5_weight: \"f32[96, 384]\", p_features_1_2_block_5_bias: \"f32[96]\", p_features_2_0_weight: \"f32[96]\", p_features_2_0_bias: \"f32[96]\", p_features_2_1_weight: \"f32[192, 96, 2, 2]\", p_features_2_1_bias: \"f32[192]\", p_features_3_0_layer_scale: \"f32[192, 1, 1]\", p_features_3_0_block_0_weight: \"f32[192, 1, 7, 7]\", p_features_3_0_block_0_bias: \"f32[192]\", p_features_3_0_block_2_weight: \"f32[192]\", p_features_3_0_block_2_bias: \"f32[192]\", p_features_3_0_block_3_weight: \"f32[768, 192]\", p_features_3_0_block_3_bias: \"f32[768]\", p_features_3_0_block_5_weight: \"f32[192, 768]\", p_features_3_0_block_5_bias: \"f32[192]\", p_features_3_1_layer_scale: \"f32[192, 1, 1]\", p_features_3_1_block_0_weight: \"f32[192, 1, 7, 7]\", p_features_3_1_block_0_bias: \"f32[192]\", p_features_3_1_block_2_weight: \"f32[192]\", p_features_3_1_block_2_bias: \"f32[192]\", p_features_3_1_block_3_weight: \"f32[768, 192]\", p_features_3_1_block_3_bias: \"f32[768]\", p_features_3_1_block_5_weight: \"f32[192, 768]\", p_features_3_1_block_5_bias: \"f32[192]\", p_features_3_2_layer_scale: \"f32[192, 1, 1]\", p_features_3_2_block_0_weight: \"f32[192, 1, 7, 7]\", p_features_3_2_block_0_bias: \"f32[192]\", p_features_3_2_block_2_weight: \"f32[192]\", p_features_3_2_block_2_bias: \"f32[192]\", p_features_3_2_block_3_weight: \"f32[768, 192]\", p_features_3_2_block_3_bias: \"f32[768]\", p_features_3_2_block_5_weight: \"f32[192, 768]\", p_features_3_2_block_5_bias: \"f32[192]\", p_features_4_0_weight: \"f32[192]\", p_features_4_0_bias: \"f32[192]\", p_features_4_1_weight: \"f32[384, 192, 2, 2]\", p_features_4_1_bias: \"f32[384]\", p_features_5_0_layer_scale: \"f32[384, 1, 1]\", p_features_5_0_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_0_block_0_bias: \"f32[384]\", p_features_5_0_block_2_weight: \"f32[384]\", p_features_5_0_block_2_bias: \"f32[384]\", p_features_5_0_block_3_weight: \"f32[1536, 384]\", p_features_5_0_block_3_bias: \"f32[1536]\", p_features_5_0_block_5_weight: \"f32[384, 1536]\", p_features_5_0_block_5_bias: \"f32[384]\", p_features_5_1_layer_scale: \"f32[384, 1, 1]\", p_features_5_1_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_1_block_0_bias: \"f32[384]\", p_features_5_1_block_2_weight: \"f32[384]\", p_features_5_1_block_2_bias: \"f32[384]\", p_features_5_1_block_3_weight: \"f32[1536, 384]\", p_features_5_1_block_3_bias: \"f32[1536]\", p_features_5_1_block_5_weight: \"f32[384, 1536]\", p_features_5_1_block_5_bias: \"f32[384]\", p_features_5_2_layer_scale: \"f32[384, 1, 1]\", p_features_5_2_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_2_block_0_bias: \"f32[384]\", p_features_5_2_block_2_weight: \"f32[384]\", p_features_5_2_block_2_bias: \"f32[384]\", p_features_5_2_block_3_weight: \"f32[1536, 384]\", p_features_5_2_block_3_bias: \"f32[1536]\", p_features_5_2_block_5_weight: \"f32[384, 1536]\", p_features_5_2_block_5_bias: \"f32[384]\", p_features_5_3_layer_scale: \"f32[384, 1, 1]\", p_features_5_3_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_3_block_0_bias: \"f32[384]\", p_features_5_3_block_2_weight: \"f32[384]\", p_features_5_3_block_2_bias: \"f32[384]\", p_features_5_3_block_3_weight: \"f32[1536, 384]\", p_features_5_3_block_3_bias: \"f32[1536]\", p_features_5_3_block_5_weight: \"f32[384, 1536]\", p_features_5_3_block_5_bias: \"f32[384]\", p_features_5_4_layer_scale: \"f32[384, 1, 1]\", p_features_5_4_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_4_block_0_bias: \"f32[384]\", p_features_5_4_block_2_weight: \"f32[384]\", p_features_5_4_block_2_bias: \"f32[384]\", p_features_5_4_block_3_weight: \"f32[1536, 384]\", p_features_5_4_block_3_bias: \"f32[1536]\", p_features_5_4_block_5_weight: \"f32[384, 1536]\", p_features_5_4_block_5_bias: \"f32[384]\", p_features_5_5_layer_scale: \"f32[384, 1, 1]\", p_features_5_5_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_5_block_0_bias: \"f32[384]\", p_features_5_5_block_2_weight: \"f32[384]\", p_features_5_5_block_2_bias: \"f32[384]\", p_features_5_5_block_3_weight: \"f32[1536, 384]\", p_features_5_5_block_3_bias: \"f32[1536]\", p_features_5_5_block_5_weight: \"f32[384, 1536]\", p_features_5_5_block_5_bias: \"f32[384]\", p_features_5_6_layer_scale: \"f32[384, 1, 1]\", p_features_5_6_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_6_block_0_bias: \"f32[384]\", p_features_5_6_block_2_weight: \"f32[384]\", p_features_5_6_block_2_bias: \"f32[384]\", p_features_5_6_block_3_weight: \"f32[1536, 384]\", p_features_5_6_block_3_bias: \"f32[1536]\", p_features_5_6_block_5_weight: \"f32[384, 1536]\", p_features_5_6_block_5_bias: \"f32[384]\", p_features_5_7_layer_scale: \"f32[384, 1, 1]\", p_features_5_7_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_7_block_0_bias: \"f32[384]\", p_features_5_7_block_2_weight: \"f32[384]\", p_features_5_7_block_2_bias: \"f32[384]\", p_features_5_7_block_3_weight: \"f32[1536, 384]\", p_features_5_7_block_3_bias: \"f32[1536]\", p_features_5_7_block_5_weight: \"f32[384, 1536]\", p_features_5_7_block_5_bias: \"f32[384]\", p_features_5_8_layer_scale: \"f32[384, 1, 1]\", p_features_5_8_block_0_weight: \"f32[384, 1, 7, 7]\", p_features_5_8_block_0_bias: \"f32[384]\", p_features_5_8_block_2_weight: \"f32[384]\", p_features_5_8_block_2_bias: \"f32[384]\", p_features_5_8_block_3_weight: \"f32[1536, 384]\", p_features_5_8_block_3_bias: \"f32[1536]\", p_features_5_8_block_5_weight: \"f32[384, 1536]\", p_features_5_8_block_5_bias: \"f32[384]\", p_features_6_0_weight: \"f32[384]\", p_features_6_0_bias: \"f32[384]\", p_features_6_1_weight: \"f32[768, 384, 2, 2]\", p_features_6_1_bias: \"f32[768]\", p_features_7_0_layer_scale: \"f32[768, 1, 1]\", p_features_7_0_block_0_weight: \"f32[768, 1, 7, 7]\", p_features_7_0_block_0_bias: \"f32[768]\", p_features_7_0_block_2_weight: \"f32[768]\", p_features_7_0_block_2_bias: \"f32[768]\", p_features_7_0_block_3_weight: \"f32[3072, 768]\", p_features_7_0_block_3_bias: \"f32[3072]\", p_features_7_0_block_5_weight: \"f32[768, 3072]\", p_features_7_0_block_5_bias: \"f32[768]\", p_features_7_1_layer_scale: \"f32[768, 1, 1]\", p_features_7_1_block_0_weight: \"f32[768, 1, 7, 7]\", p_features_7_1_block_0_bias: \"f32[768]\", p_features_7_1_block_2_weight: \"f32[768]\", p_features_7_1_block_2_bias: \"f32[768]\", p_features_7_1_block_3_weight: \"f32[3072, 768]\", p_features_7_1_block_3_bias: \"f32[3072]\", p_features_7_1_block_5_weight: \"f32[768, 3072]\", p_features_7_1_block_5_bias: \"f32[768]\", p_features_7_2_layer_scale: \"f32[768, 1, 1]\", p_features_7_2_block_0_weight: \"f32[768, 1, 7, 7]\", p_features_7_2_block_0_bias: \"f32[768]\", p_features_7_2_block_2_weight: \"f32[768]\", p_features_7_2_block_2_bias: \"f32[768]\", p_features_7_2_block_3_weight: \"f32[3072, 768]\", p_features_7_2_block_3_bias: \"f32[3072]\", p_features_7_2_block_5_weight: \"f32[768, 3072]\", p_features_7_2_block_5_bias: \"f32[768]\", p_norm_weight: \"f32[768]\", p_norm_bias: \"f32[768]\", p_classifier_weight: \"f32[10, 768]\", p_classifier_bias: \"f32[10]\", x: \"f32[s77, 3, 224, 224]\"):\n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d: \"f32[s77, 96, 56, 56]\" = torch.ops.aten.conv2d.default(x, p_features_0_0_weight, p_features_0_0_bias, [4, 4]);  x = p_features_0_0_weight = p_features_0_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:33 in forward, code: x = x.permute(0, 2, 3, 1)\n",
              "                    permute: \"f32[s77, 56, 56, 96]\" = torch.ops.aten.permute.default(conv2d, [0, 2, 3, 1]);  conv2d = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:34 in forward, code: x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
              "                    layer_norm: \"f32[s77, 56, 56, 96]\" = torch.ops.aten.layer_norm.default(permute, [96], p_features_0_1_weight, p_features_0_1_bias, 1e-06);  permute = p_features_0_1_weight = p_features_0_1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:35 in forward, code: x = x.permute(0, 3, 1, 2)\n",
              "                    permute_1: \"f32[s77, 96, 56, 56]\" = torch.ops.aten.permute.default(layer_norm, [0, 3, 1, 2]);  layer_norm = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_1: \"f32[s77, 96, 56, 56]\" = torch.ops.aten.conv2d.default(permute_1, p_features_1_0_block_0_weight, p_features_1_0_block_0_bias, [1, 1], [3, 3], [1, 1], 96);  p_features_1_0_block_0_weight = p_features_1_0_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_2: \"f32[s77, 56, 56, 96]\" = torch.ops.aten.permute.default(conv2d_1, [0, 2, 3, 1]);  conv2d_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_1: \"f32[s77, 56, 56, 96]\" = torch.ops.aten.layer_norm.default(permute_2, [96], p_features_1_0_block_2_weight, p_features_1_0_block_2_bias, 1e-06);  permute_2 = p_features_1_0_block_2_weight = p_features_1_0_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[s77, 56, (56//s77), 384]\" = torch.ops.aten.linear.default(layer_norm_1, p_features_1_0_block_3_weight, p_features_1_0_block_3_bias);  layer_norm_1 = p_features_1_0_block_3_weight = p_features_1_0_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu: \"f32[1, 56, (56//s77), 384]\" = torch.ops.aten.gelu.default(linear);  linear = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_1: \"f32[1, 56, (56//s77), 96]\" = torch.ops.aten.linear.default(gelu, p_features_1_0_block_5_weight, p_features_1_0_block_5_bias);  gelu = p_features_1_0_block_5_weight = p_features_1_0_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_3: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.permute.default(linear_1, [0, 3, 1, 2]);  linear_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_55: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.mul.Tensor(p_features_1_0_layer_scale, permute_3);  p_features_1_0_layer_scale = permute_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_90: \"f32[s77, 96, 56, (56//s77)]\" = torch.ops.aten.add.Tensor(mul_55, permute_1);  mul_55 = permute_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_2: \"f32[s77, 96, 56, (56//s77)]\" = torch.ops.aten.conv2d.default(add_90, p_features_1_1_block_0_weight, p_features_1_1_block_0_bias, [1, 1], [3, 3], [1, 1], 96);  p_features_1_1_block_0_weight = p_features_1_1_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_4: \"f32[s77, 56, (56//s77), 96]\" = torch.ops.aten.permute.default(conv2d_2, [0, 2, 3, 1]);  conv2d_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_2: \"f32[1, 56, (56//s77), 96]\" = torch.ops.aten.layer_norm.default(permute_4, [96], p_features_1_1_block_2_weight, p_features_1_1_block_2_bias, 1e-06);  permute_4 = p_features_1_1_block_2_weight = p_features_1_1_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_2: \"f32[1, 56, (56//s77), 384]\" = torch.ops.aten.linear.default(layer_norm_2, p_features_1_1_block_3_weight, p_features_1_1_block_3_bias);  layer_norm_2 = p_features_1_1_block_3_weight = p_features_1_1_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_1: \"f32[1, 56, (56//s77), 384]\" = torch.ops.aten.gelu.default(linear_2);  linear_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_3: \"f32[1, 56, (56//s77), 96]\" = torch.ops.aten.linear.default(gelu_1, p_features_1_1_block_5_weight, p_features_1_1_block_5_bias);  gelu_1 = p_features_1_1_block_5_weight = p_features_1_1_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_5: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.permute.default(linear_3, [0, 3, 1, 2]);  linear_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_98: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.mul.Tensor(p_features_1_1_layer_scale, permute_5);  p_features_1_1_layer_scale = permute_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_136: \"f32[s77, 96, 56, (56//s77)]\" = torch.ops.aten.add.Tensor(mul_98, add_90);  mul_98 = add_90 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_3: \"f32[s77, 96, 56, (56//s77)]\" = torch.ops.aten.conv2d.default(add_136, p_features_1_2_block_0_weight, p_features_1_2_block_0_bias, [1, 1], [3, 3], [1, 1], 96);  p_features_1_2_block_0_weight = p_features_1_2_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_6: \"f32[s77, 56, (56//s77), 96]\" = torch.ops.aten.permute.default(conv2d_3, [0, 2, 3, 1]);  conv2d_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_3: \"f32[1, 56, (56//s77), 96]\" = torch.ops.aten.layer_norm.default(permute_6, [96], p_features_1_2_block_2_weight, p_features_1_2_block_2_bias, 1e-06);  permute_6 = p_features_1_2_block_2_weight = p_features_1_2_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_4: \"f32[1, 56, (56//s77), 384]\" = torch.ops.aten.linear.default(layer_norm_3, p_features_1_2_block_3_weight, p_features_1_2_block_3_bias);  layer_norm_3 = p_features_1_2_block_3_weight = p_features_1_2_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_2: \"f32[1, 56, (56//s77), 384]\" = torch.ops.aten.gelu.default(linear_4);  linear_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_5: \"f32[1, 56, (56//s77), 96]\" = torch.ops.aten.linear.default(gelu_2, p_features_1_2_block_5_weight, p_features_1_2_block_5_bias);  gelu_2 = p_features_1_2_block_5_weight = p_features_1_2_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_7: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.permute.default(linear_5, [0, 3, 1, 2]);  linear_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_143: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.mul.Tensor(p_features_1_2_layer_scale, permute_7);  p_features_1_2_layer_scale = permute_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_182: \"f32[s77, 96, 56, (56//s77)]\" = torch.ops.aten.add.Tensor(mul_143, add_136);  mul_143 = add_136 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:34 in forward, code: x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
              "                    permute_9: \"f32[s77, 56, (56//s77), 96]\" = torch.ops.aten.permute.default(add_182, [0, 2, 3, 1]);  add_182 = None\n",
              "                    layer_norm_4: \"f32[1, 56, (56//s77), 96]\" = torch.ops.aten.layer_norm.default(permute_9, [96], p_features_2_0_weight, p_features_2_0_bias, 1e-06);  permute_9 = p_features_2_0_weight = p_features_2_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:35 in forward, code: x = x.permute(0, 3, 1, 2)\n",
              "                    permute_10: \"f32[1, 96, 56, (56//s77)]\" = torch.ops.aten.permute.default(layer_norm_4, [0, 3, 1, 2]);  layer_norm_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_4: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.conv2d.default(permute_10, p_features_2_1_weight, p_features_2_1_bias, [2, 2]);  permute_10 = p_features_2_1_weight = p_features_2_1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_5: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.conv2d.default(conv2d_4, p_features_3_0_block_0_weight, p_features_3_0_block_0_bias, [1, 1], [3, 3], [1, 1], 192);  p_features_3_0_block_0_weight = p_features_3_0_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_11: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.permute.default(conv2d_5, [0, 2, 3, 1]);  conv2d_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_5: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.layer_norm.default(permute_11, [192], p_features_3_0_block_2_weight, p_features_3_0_block_2_bias, 1e-06);  permute_11 = p_features_3_0_block_2_weight = p_features_3_0_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_6: \"f32[1, 28, (28//s77), 768]\" = torch.ops.aten.linear.default(layer_norm_5, p_features_3_0_block_3_weight, p_features_3_0_block_3_bias);  layer_norm_5 = p_features_3_0_block_3_weight = p_features_3_0_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_3: \"f32[1, 28, (28//s77), 768]\" = torch.ops.aten.gelu.default(linear_6);  linear_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_7: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.linear.default(gelu_3, p_features_3_0_block_5_weight, p_features_3_0_block_5_bias);  gelu_3 = p_features_3_0_block_5_weight = p_features_3_0_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_12: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.permute.default(linear_7, [0, 3, 1, 2]);  linear_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_204: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.mul.Tensor(p_features_3_0_layer_scale, permute_12);  p_features_3_0_layer_scale = permute_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_238: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.add.Tensor(mul_204, conv2d_4);  mul_204 = conv2d_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_6: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.conv2d.default(add_238, p_features_3_1_block_0_weight, p_features_3_1_block_0_bias, [1, 1], [3, 3], [1, 1], 192);  p_features_3_1_block_0_weight = p_features_3_1_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_13: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.permute.default(conv2d_6, [0, 2, 3, 1]);  conv2d_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_6: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.layer_norm.default(permute_13, [192], p_features_3_1_block_2_weight, p_features_3_1_block_2_bias, 1e-06);  permute_13 = p_features_3_1_block_2_weight = p_features_3_1_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_8: \"f32[1, 28, (28//s77), 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_features_3_1_block_3_weight, p_features_3_1_block_3_bias);  layer_norm_6 = p_features_3_1_block_3_weight = p_features_3_1_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_4: \"f32[1, 28, (28//s77), 768]\" = torch.ops.aten.gelu.default(linear_8);  linear_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_9: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.linear.default(gelu_4, p_features_3_1_block_5_weight, p_features_3_1_block_5_bias);  gelu_4 = p_features_3_1_block_5_weight = p_features_3_1_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_14: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.permute.default(linear_9, [0, 3, 1, 2]);  linear_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_249: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.mul.Tensor(p_features_3_1_layer_scale, permute_14);  p_features_3_1_layer_scale = permute_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_277: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.add.Tensor(mul_249, add_238);  mul_249 = add_238 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_7: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.conv2d.default(add_277, p_features_3_2_block_0_weight, p_features_3_2_block_0_bias, [1, 1], [3, 3], [1, 1], 192);  p_features_3_2_block_0_weight = p_features_3_2_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_15: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.permute.default(conv2d_7, [0, 2, 3, 1]);  conv2d_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_7: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.layer_norm.default(permute_15, [192], p_features_3_2_block_2_weight, p_features_3_2_block_2_bias, 1e-06);  permute_15 = p_features_3_2_block_2_weight = p_features_3_2_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_10: \"f32[1, 28, (28//s77), 768]\" = torch.ops.aten.linear.default(layer_norm_7, p_features_3_2_block_3_weight, p_features_3_2_block_3_bias);  layer_norm_7 = p_features_3_2_block_3_weight = p_features_3_2_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_5: \"f32[1, 28, (28//s77), 768]\" = torch.ops.aten.gelu.default(linear_10);  linear_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_11: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.linear.default(gelu_5, p_features_3_2_block_5_weight, p_features_3_2_block_5_bias);  gelu_5 = p_features_3_2_block_5_weight = p_features_3_2_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_16: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.permute.default(linear_11, [0, 3, 1, 2]);  linear_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_294: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.mul.Tensor(p_features_3_2_layer_scale, permute_16);  p_features_3_2_layer_scale = permute_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_316: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.add.Tensor(mul_294, add_277);  mul_294 = add_277 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:34 in forward, code: x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
              "                    permute_18: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.permute.default(add_316, [0, 2, 3, 1]);  add_316 = None\n",
              "                    layer_norm_8: \"f32[1, 28, (28//s77), 192]\" = torch.ops.aten.layer_norm.default(permute_18, [192], p_features_4_0_weight, p_features_4_0_bias, 1e-06);  permute_18 = p_features_4_0_weight = p_features_4_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:35 in forward, code: x = x.permute(0, 3, 1, 2)\n",
              "                    permute_19: \"f32[1, 192, 28, (28//s77)]\" = torch.ops.aten.permute.default(layer_norm_8, [0, 3, 1, 2]);  layer_norm_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_8: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(permute_19, p_features_4_1_weight, p_features_4_1_bias, [2, 2]);  permute_19 = p_features_4_1_weight = p_features_4_1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_9: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(conv2d_8, p_features_5_0_block_0_weight, p_features_5_0_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_0_block_0_weight = p_features_5_0_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_20: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_9, [0, 2, 3, 1]);  conv2d_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_9: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_20, [384], p_features_5_0_block_2_weight, p_features_5_0_block_2_bias, 1e-06);  permute_20 = p_features_5_0_block_2_weight = p_features_5_0_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_12: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_9, p_features_5_0_block_3_weight, p_features_5_0_block_3_bias);  layer_norm_9 = p_features_5_0_block_3_weight = p_features_5_0_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_6: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_12);  linear_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_13: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_6, p_features_5_0_block_5_weight, p_features_5_0_block_5_bias);  gelu_6 = p_features_5_0_block_5_weight = p_features_5_0_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_21: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_13, [0, 3, 1, 2]);  linear_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_355: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_0_layer_scale, permute_21);  p_features_5_0_layer_scale = permute_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_369: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_355, conv2d_8);  mul_355 = conv2d_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_10: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_369, p_features_5_1_block_0_weight, p_features_5_1_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_1_block_0_weight = p_features_5_1_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_22: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_10, [0, 2, 3, 1]);  conv2d_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_10: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_22, [384], p_features_5_1_block_2_weight, p_features_5_1_block_2_bias, 1e-06);  permute_22 = p_features_5_1_block_2_weight = p_features_5_1_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_14: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_10, p_features_5_1_block_3_weight, p_features_5_1_block_3_bias);  layer_norm_10 = p_features_5_1_block_3_weight = p_features_5_1_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_7: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_14);  linear_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_15: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_7, p_features_5_1_block_5_weight, p_features_5_1_block_5_bias);  gelu_7 = p_features_5_1_block_5_weight = p_features_5_1_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_23: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_15, [0, 3, 1, 2]);  linear_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_400: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_1_layer_scale, permute_23);  p_features_5_1_layer_scale = permute_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_408: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_400, add_369);  mul_400 = add_369 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_11: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_408, p_features_5_2_block_0_weight, p_features_5_2_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_2_block_0_weight = p_features_5_2_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_24: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_11, [0, 2, 3, 1]);  conv2d_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_11: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_24, [384], p_features_5_2_block_2_weight, p_features_5_2_block_2_bias, 1e-06);  permute_24 = p_features_5_2_block_2_weight = p_features_5_2_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_16: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_11, p_features_5_2_block_3_weight, p_features_5_2_block_3_bias);  layer_norm_11 = p_features_5_2_block_3_weight = p_features_5_2_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_8: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_16);  linear_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_17: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_8, p_features_5_2_block_5_weight, p_features_5_2_block_5_bias);  gelu_8 = p_features_5_2_block_5_weight = p_features_5_2_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_25: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_17, [0, 3, 1, 2]);  linear_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_445: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_2_layer_scale, permute_25);  p_features_5_2_layer_scale = permute_25 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_447: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_445, add_408);  mul_445 = add_408 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_12: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_447, p_features_5_3_block_0_weight, p_features_5_3_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_3_block_0_weight = p_features_5_3_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_26: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_12, [0, 2, 3, 1]);  conv2d_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_12: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_26, [384], p_features_5_3_block_2_weight, p_features_5_3_block_2_bias, 1e-06);  permute_26 = p_features_5_3_block_2_weight = p_features_5_3_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_18: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_12, p_features_5_3_block_3_weight, p_features_5_3_block_3_bias);  layer_norm_12 = p_features_5_3_block_3_weight = p_features_5_3_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_9: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_18);  linear_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_19: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_9, p_features_5_3_block_5_weight, p_features_5_3_block_5_bias);  gelu_9 = p_features_5_3_block_5_weight = p_features_5_3_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_27: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_19, [0, 3, 1, 2]);  linear_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_490: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_3_layer_scale, permute_27);  p_features_5_3_layer_scale = permute_27 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_486: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_490, add_447);  mul_490 = add_447 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_13: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_486, p_features_5_4_block_0_weight, p_features_5_4_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_4_block_0_weight = p_features_5_4_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_28: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_13, [0, 2, 3, 1]);  conv2d_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_13: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_28, [384], p_features_5_4_block_2_weight, p_features_5_4_block_2_bias, 1e-06);  permute_28 = p_features_5_4_block_2_weight = p_features_5_4_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_20: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_13, p_features_5_4_block_3_weight, p_features_5_4_block_3_bias);  layer_norm_13 = p_features_5_4_block_3_weight = p_features_5_4_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_10: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_20);  linear_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_21: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_10, p_features_5_4_block_5_weight, p_features_5_4_block_5_bias);  gelu_10 = p_features_5_4_block_5_weight = p_features_5_4_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_29: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_21, [0, 3, 1, 2]);  linear_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_535: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_4_layer_scale, permute_29);  p_features_5_4_layer_scale = permute_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_525: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_535, add_486);  mul_535 = add_486 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_14: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_525, p_features_5_5_block_0_weight, p_features_5_5_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_5_block_0_weight = p_features_5_5_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_30: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_14, [0, 2, 3, 1]);  conv2d_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_14: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_30, [384], p_features_5_5_block_2_weight, p_features_5_5_block_2_bias, 1e-06);  permute_30 = p_features_5_5_block_2_weight = p_features_5_5_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_22: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_14, p_features_5_5_block_3_weight, p_features_5_5_block_3_bias);  layer_norm_14 = p_features_5_5_block_3_weight = p_features_5_5_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_11: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_22);  linear_22 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_23: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_11, p_features_5_5_block_5_weight, p_features_5_5_block_5_bias);  gelu_11 = p_features_5_5_block_5_weight = p_features_5_5_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_31: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_23, [0, 3, 1, 2]);  linear_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_580: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_5_layer_scale, permute_31);  p_features_5_5_layer_scale = permute_31 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_564: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_580, add_525);  mul_580 = add_525 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_15: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_564, p_features_5_6_block_0_weight, p_features_5_6_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_6_block_0_weight = p_features_5_6_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_32: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_15, [0, 2, 3, 1]);  conv2d_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_15: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_32, [384], p_features_5_6_block_2_weight, p_features_5_6_block_2_bias, 1e-06);  permute_32 = p_features_5_6_block_2_weight = p_features_5_6_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_24: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_15, p_features_5_6_block_3_weight, p_features_5_6_block_3_bias);  layer_norm_15 = p_features_5_6_block_3_weight = p_features_5_6_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_12: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_24);  linear_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_25: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_12, p_features_5_6_block_5_weight, p_features_5_6_block_5_bias);  gelu_12 = p_features_5_6_block_5_weight = p_features_5_6_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_33: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_25, [0, 3, 1, 2]);  linear_25 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_625: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_6_layer_scale, permute_33);  p_features_5_6_layer_scale = permute_33 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_603: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_625, add_564);  mul_625 = add_564 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_16: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_603, p_features_5_7_block_0_weight, p_features_5_7_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_7_block_0_weight = p_features_5_7_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_34: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_16, [0, 2, 3, 1]);  conv2d_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_16: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_34, [384], p_features_5_7_block_2_weight, p_features_5_7_block_2_bias, 1e-06);  permute_34 = p_features_5_7_block_2_weight = p_features_5_7_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_26: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_16, p_features_5_7_block_3_weight, p_features_5_7_block_3_bias);  layer_norm_16 = p_features_5_7_block_3_weight = p_features_5_7_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_13: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_26);  linear_26 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_27: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_13, p_features_5_7_block_5_weight, p_features_5_7_block_5_bias);  gelu_13 = p_features_5_7_block_5_weight = p_features_5_7_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_35: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_27, [0, 3, 1, 2]);  linear_27 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_670: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_7_layer_scale, permute_35);  p_features_5_7_layer_scale = permute_35 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_642: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_670, add_603);  mul_670 = add_603 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_17: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.conv2d.default(add_642, p_features_5_8_block_0_weight, p_features_5_8_block_0_bias, [1, 1], [3, 3], [1, 1], 384);  p_features_5_8_block_0_weight = p_features_5_8_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_36: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(conv2d_17, [0, 2, 3, 1]);  conv2d_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_17: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_36, [384], p_features_5_8_block_2_weight, p_features_5_8_block_2_bias, 1e-06);  permute_36 = p_features_5_8_block_2_weight = p_features_5_8_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_28: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.linear.default(layer_norm_17, p_features_5_8_block_3_weight, p_features_5_8_block_3_bias);  layer_norm_17 = p_features_5_8_block_3_weight = p_features_5_8_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_14: \"f32[1, 14, (14//s77), 1536]\" = torch.ops.aten.gelu.default(linear_28);  linear_28 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_29: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.linear.default(gelu_14, p_features_5_8_block_5_weight, p_features_5_8_block_5_bias);  gelu_14 = p_features_5_8_block_5_weight = p_features_5_8_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_37: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(linear_29, [0, 3, 1, 2]);  linear_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_715: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.mul.Tensor(p_features_5_8_layer_scale, permute_37);  p_features_5_8_layer_scale = permute_37 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_681: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.add.Tensor(mul_715, add_642);  mul_715 = add_642 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:34 in forward, code: x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
              "                    permute_39: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.permute.default(add_681, [0, 2, 3, 1]);  add_681 = None\n",
              "                    layer_norm_18: \"f32[1, 14, (14//s77), 384]\" = torch.ops.aten.layer_norm.default(permute_39, [384], p_features_6_0_weight, p_features_6_0_bias, 1e-06);  permute_39 = p_features_6_0_weight = p_features_6_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:35 in forward, code: x = x.permute(0, 3, 1, 2)\n",
              "                    permute_40: \"f32[1, 384, 14, (14//s77)]\" = torch.ops.aten.permute.default(layer_norm_18, [0, 3, 1, 2]);  layer_norm_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_18: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.conv2d.default(permute_40, p_features_6_1_weight, p_features_6_1_bias, [2, 2]);  permute_40 = p_features_6_1_weight = p_features_6_1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_19: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.conv2d.default(conv2d_18, p_features_7_0_block_0_weight, p_features_7_0_block_0_bias, [1, 1], [3, 3], [1, 1], 768);  p_features_7_0_block_0_weight = p_features_7_0_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_41: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.permute.default(conv2d_19, [0, 2, 3, 1]);  conv2d_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_19: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.layer_norm.default(permute_41, [768], p_features_7_0_block_2_weight, p_features_7_0_block_2_bias, 1e-06);  permute_41 = p_features_7_0_block_2_weight = p_features_7_0_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_30: \"f32[1, 7, (7//s77), 3072]\" = torch.ops.aten.linear.default(layer_norm_19, p_features_7_0_block_3_weight, p_features_7_0_block_3_bias);  layer_norm_19 = p_features_7_0_block_3_weight = p_features_7_0_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_15: \"f32[1, 7, (7//s77), 3072]\" = torch.ops.aten.gelu.default(linear_30);  linear_30 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_31: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.linear.default(gelu_15, p_features_7_0_block_5_weight, p_features_7_0_block_5_bias);  gelu_15 = p_features_7_0_block_5_weight = p_features_7_0_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_42: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.permute.default(linear_31, [0, 3, 1, 2]);  linear_31 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_776: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.mul.Tensor(p_features_7_0_layer_scale, permute_42);  p_features_7_0_layer_scale = permute_42 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_734: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.add.Tensor(mul_776, conv2d_18);  mul_776 = conv2d_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_20: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.conv2d.default(add_734, p_features_7_1_block_0_weight, p_features_7_1_block_0_bias, [1, 1], [3, 3], [1, 1], 768);  p_features_7_1_block_0_weight = p_features_7_1_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_43: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.permute.default(conv2d_20, [0, 2, 3, 1]);  conv2d_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_20: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.layer_norm.default(permute_43, [768], p_features_7_1_block_2_weight, p_features_7_1_block_2_bias, 1e-06);  permute_43 = p_features_7_1_block_2_weight = p_features_7_1_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_32: \"f32[1, 7, (7//s77), 3072]\" = torch.ops.aten.linear.default(layer_norm_20, p_features_7_1_block_3_weight, p_features_7_1_block_3_bias);  layer_norm_20 = p_features_7_1_block_3_weight = p_features_7_1_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_16: \"f32[1, 7, (7//s77), 3072]\" = torch.ops.aten.gelu.default(linear_32);  linear_32 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_33: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.linear.default(gelu_16, p_features_7_1_block_5_weight, p_features_7_1_block_5_bias);  gelu_16 = p_features_7_1_block_5_weight = p_features_7_1_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_44: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.permute.default(linear_33, [0, 3, 1, 2]);  linear_33 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_821: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.mul.Tensor(p_features_7_1_layer_scale, permute_44);  p_features_7_1_layer_scale = permute_44 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_773: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.add.Tensor(mul_821, add_734);  mul_821 = add_734 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_21: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.conv2d.default(add_773, p_features_7_2_block_0_weight, p_features_7_2_block_0_bias, [1, 1], [3, 3], [1, 1], 768);  p_features_7_2_block_0_weight = p_features_7_2_block_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_45: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.permute.default(conv2d_21, [0, 2, 3, 1]);  conv2d_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_21: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.layer_norm.default(permute_45, [768], p_features_7_2_block_2_weight, p_features_7_2_block_2_bias, 1e-06);  permute_45 = p_features_7_2_block_2_weight = p_features_7_2_block_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_34: \"f32[1, 7, (7//s77), 3072]\" = torch.ops.aten.linear.default(layer_norm_21, p_features_7_2_block_3_weight, p_features_7_2_block_3_bias);  layer_norm_21 = p_features_7_2_block_3_weight = p_features_7_2_block_3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:816 in forward, code: return F.gelu(input, approximate=self.approximate)\n",
              "                    gelu_17: \"f32[1, 7, (7//s77), 3072]\" = torch.ops.aten.gelu.default(linear_34);  linear_34 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_35: \"f32[1, 7, (7//s77), 768]\" = torch.ops.aten.linear.default(gelu_17, p_features_7_2_block_5_weight, p_features_7_2_block_5_bias);  gelu_17 = p_features_7_2_block_5_weight = p_features_7_2_block_5_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/ops/misc.py:321 in forward, code: return torch.permute(x, self.dims)\n",
              "                    permute_46: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.permute.default(linear_35, [0, 3, 1, 2]);  linear_35 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:64 in forward, code: result = self.layer_scale * self.block(input)\n",
              "                    mul_866: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.mul.Tensor(p_features_7_2_layer_scale, permute_46);  p_features_7_2_layer_scale = permute_46 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py:66 in forward, code: result += input\n",
              "                    add_812: \"f32[1, 768, 7, (7//s77)]\" = torch.ops.aten.add.Tensor(mul_866, add_773);  mul_866 = add_773 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
              "                    mean: \"f32[1, 768, 1, 1]\" = torch.ops.aten.mean.dim(add_812, [-1, -2], True);  add_812 = None\n",
              "                    as_strided: \"f32[1, 768, 1, 1]\" = torch.ops.aten.as_strided.default(mean, [1, 768, 1, 1], [768, 1, 768, 768]);  mean = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/flatten.py:56 in forward, code: return input.flatten(self.start_dim, self.end_dim)\n",
              "                    view: \"f32[1, 768]\" = torch.ops.aten.view.default(as_strided, [1, 768]);  as_strided = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_22: \"f32[1, 768]\" = torch.ops.aten.layer_norm.default(view, [768], p_norm_weight, p_norm_bias);  view = p_norm_weight = p_norm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_36: \"f32[1, 10]\" = torch.ops.aten.linear.default(layer_norm_22, p_classifier_weight, p_classifier_bias);  layer_norm_22 = p_classifier_weight = p_classifier_bias = None\n",
              "                    return (linear_36,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_features_0_0_weight: PARAMETER target='features.0.0.weight'\n",
              "            p_features_0_0_bias: PARAMETER target='features.0.0.bias'\n",
              "            p_features_0_1_weight: PARAMETER target='features.0.1.weight'\n",
              "            p_features_0_1_bias: PARAMETER target='features.0.1.bias'\n",
              "            p_features_1_0_layer_scale: PARAMETER target='features.1.0.layer_scale'\n",
              "            p_features_1_0_block_0_weight: PARAMETER target='features.1.0.block.0.weight'\n",
              "            p_features_1_0_block_0_bias: PARAMETER target='features.1.0.block.0.bias'\n",
              "            p_features_1_0_block_2_weight: PARAMETER target='features.1.0.block.2.weight'\n",
              "            p_features_1_0_block_2_bias: PARAMETER target='features.1.0.block.2.bias'\n",
              "            p_features_1_0_block_3_weight: PARAMETER target='features.1.0.block.3.weight'\n",
              "            p_features_1_0_block_3_bias: PARAMETER target='features.1.0.block.3.bias'\n",
              "            p_features_1_0_block_5_weight: PARAMETER target='features.1.0.block.5.weight'\n",
              "            p_features_1_0_block_5_bias: PARAMETER target='features.1.0.block.5.bias'\n",
              "            p_features_1_1_layer_scale: PARAMETER target='features.1.1.layer_scale'\n",
              "            p_features_1_1_block_0_weight: PARAMETER target='features.1.1.block.0.weight'\n",
              "            p_features_1_1_block_0_bias: PARAMETER target='features.1.1.block.0.bias'\n",
              "            p_features_1_1_block_2_weight: PARAMETER target='features.1.1.block.2.weight'\n",
              "            p_features_1_1_block_2_bias: PARAMETER target='features.1.1.block.2.bias'\n",
              "            p_features_1_1_block_3_weight: PARAMETER target='features.1.1.block.3.weight'\n",
              "            p_features_1_1_block_3_bias: PARAMETER target='features.1.1.block.3.bias'\n",
              "            p_features_1_1_block_5_weight: PARAMETER target='features.1.1.block.5.weight'\n",
              "            p_features_1_1_block_5_bias: PARAMETER target='features.1.1.block.5.bias'\n",
              "            p_features_1_2_layer_scale: PARAMETER target='features.1.2.layer_scale'\n",
              "            p_features_1_2_block_0_weight: PARAMETER target='features.1.2.block.0.weight'\n",
              "            p_features_1_2_block_0_bias: PARAMETER target='features.1.2.block.0.bias'\n",
              "            p_features_1_2_block_2_weight: PARAMETER target='features.1.2.block.2.weight'\n",
              "            p_features_1_2_block_2_bias: PARAMETER target='features.1.2.block.2.bias'\n",
              "            p_features_1_2_block_3_weight: PARAMETER target='features.1.2.block.3.weight'\n",
              "            p_features_1_2_block_3_bias: PARAMETER target='features.1.2.block.3.bias'\n",
              "            p_features_1_2_block_5_weight: PARAMETER target='features.1.2.block.5.weight'\n",
              "            p_features_1_2_block_5_bias: PARAMETER target='features.1.2.block.5.bias'\n",
              "            p_features_2_0_weight: PARAMETER target='features.2.0.weight'\n",
              "            p_features_2_0_bias: PARAMETER target='features.2.0.bias'\n",
              "            p_features_2_1_weight: PARAMETER target='features.2.1.weight'\n",
              "            p_features_2_1_bias: PARAMETER target='features.2.1.bias'\n",
              "            p_features_3_0_layer_scale: PARAMETER target='features.3.0.layer_scale'\n",
              "            p_features_3_0_block_0_weight: PARAMETER target='features.3.0.block.0.weight'\n",
              "            p_features_3_0_block_0_bias: PARAMETER target='features.3.0.block.0.bias'\n",
              "            p_features_3_0_block_2_weight: PARAMETER target='features.3.0.block.2.weight'\n",
              "            p_features_3_0_block_2_bias: PARAMETER target='features.3.0.block.2.bias'\n",
              "            p_features_3_0_block_3_weight: PARAMETER target='features.3.0.block.3.weight'\n",
              "            p_features_3_0_block_3_bias: PARAMETER target='features.3.0.block.3.bias'\n",
              "            p_features_3_0_block_5_weight: PARAMETER target='features.3.0.block.5.weight'\n",
              "            p_features_3_0_block_5_bias: PARAMETER target='features.3.0.block.5.bias'\n",
              "            p_features_3_1_layer_scale: PARAMETER target='features.3.1.layer_scale'\n",
              "            p_features_3_1_block_0_weight: PARAMETER target='features.3.1.block.0.weight'\n",
              "            p_features_3_1_block_0_bias: PARAMETER target='features.3.1.block.0.bias'\n",
              "            p_features_3_1_block_2_weight: PARAMETER target='features.3.1.block.2.weight'\n",
              "            p_features_3_1_block_2_bias: PARAMETER target='features.3.1.block.2.bias'\n",
              "            p_features_3_1_block_3_weight: PARAMETER target='features.3.1.block.3.weight'\n",
              "            p_features_3_1_block_3_bias: PARAMETER target='features.3.1.block.3.bias'\n",
              "            p_features_3_1_block_5_weight: PARAMETER target='features.3.1.block.5.weight'\n",
              "            p_features_3_1_block_5_bias: PARAMETER target='features.3.1.block.5.bias'\n",
              "            p_features_3_2_layer_scale: PARAMETER target='features.3.2.layer_scale'\n",
              "            p_features_3_2_block_0_weight: PARAMETER target='features.3.2.block.0.weight'\n",
              "            p_features_3_2_block_0_bias: PARAMETER target='features.3.2.block.0.bias'\n",
              "            p_features_3_2_block_2_weight: PARAMETER target='features.3.2.block.2.weight'\n",
              "            p_features_3_2_block_2_bias: PARAMETER target='features.3.2.block.2.bias'\n",
              "            p_features_3_2_block_3_weight: PARAMETER target='features.3.2.block.3.weight'\n",
              "            p_features_3_2_block_3_bias: PARAMETER target='features.3.2.block.3.bias'\n",
              "            p_features_3_2_block_5_weight: PARAMETER target='features.3.2.block.5.weight'\n",
              "            p_features_3_2_block_5_bias: PARAMETER target='features.3.2.block.5.bias'\n",
              "            p_features_4_0_weight: PARAMETER target='features.4.0.weight'\n",
              "            p_features_4_0_bias: PARAMETER target='features.4.0.bias'\n",
              "            p_features_4_1_weight: PARAMETER target='features.4.1.weight'\n",
              "            p_features_4_1_bias: PARAMETER target='features.4.1.bias'\n",
              "            p_features_5_0_layer_scale: PARAMETER target='features.5.0.layer_scale'\n",
              "            p_features_5_0_block_0_weight: PARAMETER target='features.5.0.block.0.weight'\n",
              "            p_features_5_0_block_0_bias: PARAMETER target='features.5.0.block.0.bias'\n",
              "            p_features_5_0_block_2_weight: PARAMETER target='features.5.0.block.2.weight'\n",
              "            p_features_5_0_block_2_bias: PARAMETER target='features.5.0.block.2.bias'\n",
              "            p_features_5_0_block_3_weight: PARAMETER target='features.5.0.block.3.weight'\n",
              "            p_features_5_0_block_3_bias: PARAMETER target='features.5.0.block.3.bias'\n",
              "            p_features_5_0_block_5_weight: PARAMETER target='features.5.0.block.5.weight'\n",
              "            p_features_5_0_block_5_bias: PARAMETER target='features.5.0.block.5.bias'\n",
              "            p_features_5_1_layer_scale: PARAMETER target='features.5.1.layer_scale'\n",
              "            p_features_5_1_block_0_weight: PARAMETER target='features.5.1.block.0.weight'\n",
              "            p_features_5_1_block_0_bias: PARAMETER target='features.5.1.block.0.bias'\n",
              "            p_features_5_1_block_2_weight: PARAMETER target='features.5.1.block.2.weight'\n",
              "            p_features_5_1_block_2_bias: PARAMETER target='features.5.1.block.2.bias'\n",
              "            p_features_5_1_block_3_weight: PARAMETER target='features.5.1.block.3.weight'\n",
              "            p_features_5_1_block_3_bias: PARAMETER target='features.5.1.block.3.bias'\n",
              "            p_features_5_1_block_5_weight: PARAMETER target='features.5.1.block.5.weight'\n",
              "            p_features_5_1_block_5_bias: PARAMETER target='features.5.1.block.5.bias'\n",
              "            p_features_5_2_layer_scale: PARAMETER target='features.5.2.layer_scale'\n",
              "            p_features_5_2_block_0_weight: PARAMETER target='features.5.2.block.0.weight'\n",
              "            p_features_5_2_block_0_bias: PARAMETER target='features.5.2.block.0.bias'\n",
              "            p_features_5_2_block_2_weight: PARAMETER target='features.5.2.block.2.weight'\n",
              "            p_features_5_2_block_2_bias: PARAMETER target='features.5.2.block.2.bias'\n",
              "            p_features_5_2_block_3_weight: PARAMETER target='features.5.2.block.3.weight'\n",
              "            p_features_5_2_block_3_bias: PARAMETER target='features.5.2.block.3.bias'\n",
              "            p_features_5_2_block_5_weight: PARAMETER target='features.5.2.block.5.weight'\n",
              "            p_features_5_2_block_5_bias: PARAMETER target='features.5.2.block.5.bias'\n",
              "            p_features_5_3_layer_scale: PARAMETER target='features.5.3.layer_scale'\n",
              "            p_features_5_3_block_0_weight: PARAMETER target='features.5.3.block.0.weight'\n",
              "            p_features_5_3_block_0_bias: PARAMETER target='features.5.3.block.0.bias'\n",
              "            p_features_5_3_block_2_weight: PARAMETER target='features.5.3.block.2.weight'\n",
              "            p_features_5_3_block_2_bias: PARAMETER target='features.5.3.block.2.bias'\n",
              "            p_features_5_3_block_3_weight: PARAMETER target='features.5.3.block.3.weight'\n",
              "            p_features_5_3_block_3_bias: PARAMETER target='features.5.3.block.3.bias'\n",
              "            p_features_5_3_block_5_weight: PARAMETER target='features.5.3.block.5.weight'\n",
              "            p_features_5_3_block_5_bias: PARAMETER target='features.5.3.block.5.bias'\n",
              "            p_features_5_4_layer_scale: PARAMETER target='features.5.4.layer_scale'\n",
              "            p_features_5_4_block_0_weight: PARAMETER target='features.5.4.block.0.weight'\n",
              "            p_features_5_4_block_0_bias: PARAMETER target='features.5.4.block.0.bias'\n",
              "            p_features_5_4_block_2_weight: PARAMETER target='features.5.4.block.2.weight'\n",
              "            p_features_5_4_block_2_bias: PARAMETER target='features.5.4.block.2.bias'\n",
              "            p_features_5_4_block_3_weight: PARAMETER target='features.5.4.block.3.weight'\n",
              "            p_features_5_4_block_3_bias: PARAMETER target='features.5.4.block.3.bias'\n",
              "            p_features_5_4_block_5_weight: PARAMETER target='features.5.4.block.5.weight'\n",
              "            p_features_5_4_block_5_bias: PARAMETER target='features.5.4.block.5.bias'\n",
              "            p_features_5_5_layer_scale: PARAMETER target='features.5.5.layer_scale'\n",
              "            p_features_5_5_block_0_weight: PARAMETER target='features.5.5.block.0.weight'\n",
              "            p_features_5_5_block_0_bias: PARAMETER target='features.5.5.block.0.bias'\n",
              "            p_features_5_5_block_2_weight: PARAMETER target='features.5.5.block.2.weight'\n",
              "            p_features_5_5_block_2_bias: PARAMETER target='features.5.5.block.2.bias'\n",
              "            p_features_5_5_block_3_weight: PARAMETER target='features.5.5.block.3.weight'\n",
              "            p_features_5_5_block_3_bias: PARAMETER target='features.5.5.block.3.bias'\n",
              "            p_features_5_5_block_5_weight: PARAMETER target='features.5.5.block.5.weight'\n",
              "            p_features_5_5_block_5_bias: PARAMETER target='features.5.5.block.5.bias'\n",
              "            p_features_5_6_layer_scale: PARAMETER target='features.5.6.layer_scale'\n",
              "            p_features_5_6_block_0_weight: PARAMETER target='features.5.6.block.0.weight'\n",
              "            p_features_5_6_block_0_bias: PARAMETER target='features.5.6.block.0.bias'\n",
              "            p_features_5_6_block_2_weight: PARAMETER target='features.5.6.block.2.weight'\n",
              "            p_features_5_6_block_2_bias: PARAMETER target='features.5.6.block.2.bias'\n",
              "            p_features_5_6_block_3_weight: PARAMETER target='features.5.6.block.3.weight'\n",
              "            p_features_5_6_block_3_bias: PARAMETER target='features.5.6.block.3.bias'\n",
              "            p_features_5_6_block_5_weight: PARAMETER target='features.5.6.block.5.weight'\n",
              "            p_features_5_6_block_5_bias: PARAMETER target='features.5.6.block.5.bias'\n",
              "            p_features_5_7_layer_scale: PARAMETER target='features.5.7.layer_scale'\n",
              "            p_features_5_7_block_0_weight: PARAMETER target='features.5.7.block.0.weight'\n",
              "            p_features_5_7_block_0_bias: PARAMETER target='features.5.7.block.0.bias'\n",
              "            p_features_5_7_block_2_weight: PARAMETER target='features.5.7.block.2.weight'\n",
              "            p_features_5_7_block_2_bias: PARAMETER target='features.5.7.block.2.bias'\n",
              "            p_features_5_7_block_3_weight: PARAMETER target='features.5.7.block.3.weight'\n",
              "            p_features_5_7_block_3_bias: PARAMETER target='features.5.7.block.3.bias'\n",
              "            p_features_5_7_block_5_weight: PARAMETER target='features.5.7.block.5.weight'\n",
              "            p_features_5_7_block_5_bias: PARAMETER target='features.5.7.block.5.bias'\n",
              "            p_features_5_8_layer_scale: PARAMETER target='features.5.8.layer_scale'\n",
              "            p_features_5_8_block_0_weight: PARAMETER target='features.5.8.block.0.weight'\n",
              "            p_features_5_8_block_0_bias: PARAMETER target='features.5.8.block.0.bias'\n",
              "            p_features_5_8_block_2_weight: PARAMETER target='features.5.8.block.2.weight'\n",
              "            p_features_5_8_block_2_bias: PARAMETER target='features.5.8.block.2.bias'\n",
              "            p_features_5_8_block_3_weight: PARAMETER target='features.5.8.block.3.weight'\n",
              "            p_features_5_8_block_3_bias: PARAMETER target='features.5.8.block.3.bias'\n",
              "            p_features_5_8_block_5_weight: PARAMETER target='features.5.8.block.5.weight'\n",
              "            p_features_5_8_block_5_bias: PARAMETER target='features.5.8.block.5.bias'\n",
              "            p_features_6_0_weight: PARAMETER target='features.6.0.weight'\n",
              "            p_features_6_0_bias: PARAMETER target='features.6.0.bias'\n",
              "            p_features_6_1_weight: PARAMETER target='features.6.1.weight'\n",
              "            p_features_6_1_bias: PARAMETER target='features.6.1.bias'\n",
              "            p_features_7_0_layer_scale: PARAMETER target='features.7.0.layer_scale'\n",
              "            p_features_7_0_block_0_weight: PARAMETER target='features.7.0.block.0.weight'\n",
              "            p_features_7_0_block_0_bias: PARAMETER target='features.7.0.block.0.bias'\n",
              "            p_features_7_0_block_2_weight: PARAMETER target='features.7.0.block.2.weight'\n",
              "            p_features_7_0_block_2_bias: PARAMETER target='features.7.0.block.2.bias'\n",
              "            p_features_7_0_block_3_weight: PARAMETER target='features.7.0.block.3.weight'\n",
              "            p_features_7_0_block_3_bias: PARAMETER target='features.7.0.block.3.bias'\n",
              "            p_features_7_0_block_5_weight: PARAMETER target='features.7.0.block.5.weight'\n",
              "            p_features_7_0_block_5_bias: PARAMETER target='features.7.0.block.5.bias'\n",
              "            p_features_7_1_layer_scale: PARAMETER target='features.7.1.layer_scale'\n",
              "            p_features_7_1_block_0_weight: PARAMETER target='features.7.1.block.0.weight'\n",
              "            p_features_7_1_block_0_bias: PARAMETER target='features.7.1.block.0.bias'\n",
              "            p_features_7_1_block_2_weight: PARAMETER target='features.7.1.block.2.weight'\n",
              "            p_features_7_1_block_2_bias: PARAMETER target='features.7.1.block.2.bias'\n",
              "            p_features_7_1_block_3_weight: PARAMETER target='features.7.1.block.3.weight'\n",
              "            p_features_7_1_block_3_bias: PARAMETER target='features.7.1.block.3.bias'\n",
              "            p_features_7_1_block_5_weight: PARAMETER target='features.7.1.block.5.weight'\n",
              "            p_features_7_1_block_5_bias: PARAMETER target='features.7.1.block.5.bias'\n",
              "            p_features_7_2_layer_scale: PARAMETER target='features.7.2.layer_scale'\n",
              "            p_features_7_2_block_0_weight: PARAMETER target='features.7.2.block.0.weight'\n",
              "            p_features_7_2_block_0_bias: PARAMETER target='features.7.2.block.0.bias'\n",
              "            p_features_7_2_block_2_weight: PARAMETER target='features.7.2.block.2.weight'\n",
              "            p_features_7_2_block_2_bias: PARAMETER target='features.7.2.block.2.bias'\n",
              "            p_features_7_2_block_3_weight: PARAMETER target='features.7.2.block.3.weight'\n",
              "            p_features_7_2_block_3_bias: PARAMETER target='features.7.2.block.3.bias'\n",
              "            p_features_7_2_block_5_weight: PARAMETER target='features.7.2.block.5.weight'\n",
              "            p_features_7_2_block_5_bias: PARAMETER target='features.7.2.block.5.bias'\n",
              "            p_norm_weight: PARAMETER target='norm.weight'\n",
              "            p_norm_bias: PARAMETER target='norm.bias'\n",
              "            p_classifier_weight: PARAMETER target='classifier.weight'\n",
              "            p_classifier_bias: PARAMETER target='classifier.bias'\n",
              "            x: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            linear_36: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {s77: VR[0, 2]}\n",
              "\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "onnx_model=onnx.load('eurosat.onnx')\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print('succeeded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHqcbGgY36Hi",
        "outputId": "15229ad4-8fa5-474b-8e99-e857aaa4de12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('/content/eurosat.onnx','/content/drive/MyDrive/opokuml_geosight/eurosat.onnx')\n",
        "print('save completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HYP4zDrRW4A",
        "outputId": "754fc254-51f0-487c-fe58-7efe09847074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KKBi51zau0h",
        "outputId": "4fb96c8b-b430-42dc-b586-7426be4a706c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "session=ort.InferenceSession(\"/content/eurosat.onnx\")\n",
        "\n",
        "# Get one batch from the test loader\n",
        "test_image, test_label = next(iter(test_loader))\n",
        "\n",
        "# Take the first image in the batch\n",
        "test_tensor = test_image[0].unsqueeze(0)   # shape (1,3,224,224)\n",
        "true_label = test_label[0].item()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pytorch_output = model(test_tensor.to(device))\n",
        "\n",
        "print(\"‚úÖ True label:\", true_label)\n",
        "print(\"PyTorch prediction:\", pytorch_output.argmax(dim=1).item())\n",
        "\n",
        "onnx_output = session.run(None, {\"input\": test_tensor.cpu().numpy()})[0]\n",
        "\n",
        "print(\"ONNX prediction:\", np.argmax(onnx_output, axis=1)[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUtu9iO0bDxE",
        "outputId": "9e39a698-230f-4bf3-b30d-542ff1da2b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ True label: 6\n",
            "PyTorch prediction: 6\n",
            "ONNX prediction: 6\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM6jBMJwptn8VtucjeipikY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}